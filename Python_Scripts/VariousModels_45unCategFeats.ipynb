{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4970f1f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:13:29.705581Z",
     "start_time": "2023-02-25T08:13:23.130037Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ea6439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:13:31.827158Z",
     "start_time": "2023-02-25T08:13:31.541900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\PPMI_Data\\Excels\\CollaborativeFiltering\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPRDX</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Apathy</th>\n",
       "      <th>Benton</th>\n",
       "      <th>Clock</th>\n",
       "      <th>Cognition</th>\n",
       "      <th>COGSTATE</th>\n",
       "      <th>Constipate</th>\n",
       "      <th>Depress</th>\n",
       "      <th>DopaDefic</th>\n",
       "      <th>...</th>\n",
       "      <th>Semantic</th>\n",
       "      <th>SleepDay</th>\n",
       "      <th>SleepNight</th>\n",
       "      <th>STAIA</th>\n",
       "      <th>STAIS</th>\n",
       "      <th>Symbol_Digit</th>\n",
       "      <th>Trail_Making_A</th>\n",
       "      <th>Trail_Making_B</th>\n",
       "      <th>UPSIT</th>\n",
       "      <th>Urine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>59</td>\n",
       "      <td>47.5</td>\n",
       "      <td>110</td>\n",
       "      <td>204</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    APPRDX  Anxiety  Apathy  Benton  Clock  Cognition  COGSTATE  Constipate  \\\n",
       "0  Patient        1       0   12.16      7          1         1           1   \n",
       "1  Patient        1       1    7.76      6          1         1           0   \n",
       "\n",
       "   Depress  DopaDefic  ...  Semantic  SleepDay  SleepNight  STAIA  STAIS  \\\n",
       "0        1          0  ...        57         1           0     45     59   \n",
       "1        0          0  ...        36         1           3     40     39   \n",
       "\n",
       "   Symbol_Digit  Trail_Making_A  Trail_Making_B  UPSIT  Urine  \n",
       "0          47.5             110             204     17      1  \n",
       "1          52.0              27              52      9      0  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd Z:\\PPMI_Data\\Excels\\CollaborativeFiltering\n",
    "NonMot = pd.read_csv('Feats45_unCategAge_APPRDX.csv')\n",
    "NonMot1 = NonMot.drop(['PATNO', 'Patient_ID', 'Age'], axis = 1)\n",
    "NonMot1['APPRDX'] = NonMot1['APPRDX'].replace([1], 'Patient')\n",
    "NonMot1['APPRDX'] = NonMot1['APPRDX'].replace([2], 'Healthy')\n",
    "NonMot1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505ca38",
   "metadata": {},
   "source": [
    "# Naive Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d12a10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T06:18:20.252608Z",
     "start_time": "2023-02-15T06:18:15.053475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Mean accuracy: 0.716\n",
      "2\n",
      "Mean accuracy: 0.72\n",
      "3\n",
      "Mean accuracy: 0.72\n",
      "4\n",
      "Mean accuracy: 0.704\n",
      "5\n",
      "Mean accuracy: 0.7\n",
      "6\n",
      "Mean accuracy: 0.72\n",
      "7\n",
      "Mean accuracy: 0.712\n",
      "8\n",
      "Mean accuracy: 0.712\n",
      "9\n",
      "Mean accuracy: 0.712\n",
      "10\n",
      "Mean accuracy: 0.732\n",
      "11\n",
      "Mean accuracy: 0.716\n",
      "12\n",
      "Mean accuracy: 0.716\n",
      "13\n",
      "Mean accuracy: 0.708\n",
      "14\n",
      "Mean accuracy: 0.716\n",
      "15\n",
      "Mean accuracy: 0.712\n",
      "16\n",
      "Mean accuracy: 0.696\n",
      "17\n",
      "Mean accuracy: 0.708\n",
      "18\n",
      "Mean accuracy: 0.696\n",
      "19\n",
      "Mean accuracy: 0.716\n",
      "20\n",
      "Mean accuracy: 0.7\n",
      "21\n",
      "Mean accuracy: 0.7\n",
      "22\n",
      "Mean accuracy: 0.728\n",
      "23\n",
      "Mean accuracy: 0.72\n",
      "24\n",
      "Mean accuracy: 0.708\n",
      "25\n",
      "Mean accuracy: 0.688\n",
      "26\n",
      "Mean accuracy: 0.708\n",
      "27\n",
      "Mean accuracy: 0.716\n",
      "28\n",
      "Mean accuracy: 0.704\n",
      "29\n",
      "Mean accuracy: 0.708\n",
      "30\n",
      "Mean accuracy: 0.716\n",
      "31\n",
      "Mean accuracy: 0.7\n",
      "32\n",
      "Mean accuracy: 0.704\n",
      "33\n",
      "Mean accuracy: 0.708\n",
      "34\n",
      "Mean accuracy: 0.708\n",
      "35\n",
      "Mean accuracy: 0.716\n",
      "36\n",
      "Mean accuracy: 0.712\n",
      "37\n",
      "Mean accuracy: 0.708\n",
      "38\n",
      "Mean accuracy: 0.704\n",
      "39\n",
      "Mean accuracy: 0.704\n",
      "40\n",
      "Mean accuracy: 0.712\n",
      "41\n",
      "Mean accuracy: 0.716\n",
      "42\n",
      "Mean accuracy: 0.728\n",
      "43\n",
      "Mean accuracy: 0.704\n",
      "44\n",
      "Mean accuracy: 0.724\n",
      "45\n",
      "Mean accuracy: 0.728\n",
      "46\n",
      "Mean accuracy: 0.708\n",
      "47\n",
      "Mean accuracy: 0.712\n",
      "48\n",
      "Mean accuracy: 0.724\n",
      "49\n",
      "Mean accuracy: 0.716\n",
      "50\n",
      "Mean accuracy: 0.708\n",
      "51\n",
      "Mean accuracy: 0.716\n",
      "52\n",
      "Mean accuracy: 0.688\n",
      "53\n",
      "Mean accuracy: 0.712\n",
      "54\n",
      "Mean accuracy: 0.732\n",
      "55\n",
      "Mean accuracy: 0.708\n",
      "56\n",
      "Mean accuracy: 0.708\n",
      "57\n",
      "Mean accuracy: 0.712\n",
      "58\n",
      "Mean accuracy: 0.724\n",
      "59\n",
      "Mean accuracy: 0.716\n",
      "60\n",
      "Mean accuracy: 0.704\n",
      "61\n",
      "Mean accuracy: 0.712\n",
      "62\n",
      "Mean accuracy: 0.724\n",
      "63\n",
      "Mean accuracy: 0.728\n",
      "64\n",
      "Mean accuracy: 0.732\n",
      "65\n",
      "Mean accuracy: 0.7\n",
      "66\n",
      "Mean accuracy: 0.732\n",
      "67\n",
      "Mean accuracy: 0.716\n",
      "68\n",
      "Mean accuracy: 0.732\n",
      "69\n",
      "Mean accuracy: 0.72\n",
      "70\n",
      "Mean accuracy: 0.712\n",
      "71\n",
      "Mean accuracy: 0.724\n",
      "72\n",
      "Mean accuracy: 0.716\n",
      "73\n",
      "Mean accuracy: 0.704\n",
      "74\n",
      "Mean accuracy: 0.712\n",
      "75\n",
      "Mean accuracy: 0.724\n",
      "76\n",
      "Mean accuracy: 0.72\n",
      "77\n",
      "Mean accuracy: 0.72\n",
      "78\n",
      "Mean accuracy: 0.72\n",
      "79\n",
      "Mean accuracy: 0.716\n",
      "80\n",
      "Mean accuracy: 0.708\n",
      "81\n",
      "Mean accuracy: 0.732\n",
      "82\n",
      "Mean accuracy: 0.704\n",
      "83\n",
      "Mean accuracy: 0.716\n",
      "84\n",
      "Mean accuracy: 0.72\n",
      "85\n",
      "Mean accuracy: 0.716\n",
      "86\n",
      "Mean accuracy: 0.724\n",
      "87\n",
      "Mean accuracy: 0.724\n",
      "88\n",
      "Mean accuracy: 0.712\n",
      "89\n",
      "Mean accuracy: 0.704\n",
      "90\n",
      "Mean accuracy: 0.696\n",
      "91\n",
      "Mean accuracy: 0.712\n",
      "92\n",
      "Mean accuracy: 0.736\n",
      "93\n",
      "Mean accuracy: 0.724\n",
      "94\n",
      "Mean accuracy: 0.724\n",
      "95\n",
      "Mean accuracy: 0.72\n",
      "96\n",
      "Mean accuracy: 0.708\n",
      "97\n",
      "Mean accuracy: 0.716\n",
      "98\n",
      "Mean accuracy: 0.708\n",
      "99\n",
      "Mean accuracy: 0.728\n",
      "100\n",
      "Mean accuracy: 0.708\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kfold.split(NonMot1.drop('APPRDX', axis=1), NonMot1['APPRDX']):\n",
    "        train_data, test_data = NonMot1.iloc[train_index].drop('APPRDX', axis=1), NonMot1.iloc[test_index].drop('APPRDX', axis=1)\n",
    "        train_labels, test_labels = NonMot1.iloc[train_index]['APPRDX'], NonMot1.iloc[test_index]['APPRDX']\n",
    "    \n",
    "        nb_model = GaussianNB()\n",
    "        nb_model.fit(train_data, train_labels)\n",
    "    \n",
    "        predictions = nb_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(f'Mean accuracy: {mean_accuracy}')\n",
    "    output.append(mean_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100NaiveBayes_10fold.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f420e4a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:53:31.098518Z",
     "start_time": "2023-02-15T04:53:30.782073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.66\n",
      "Accuracy for column Apathy: 0.42\n",
      "Accuracy for column Benton: 0.68\n",
      "Accuracy for column Clock: 0.62\n",
      "Accuracy for column Cognition: 0.62\n",
      "Accuracy for column COGSTATE: 0.5\n",
      "Accuracy for column Constipate: 0.7\n",
      "Accuracy for column Depress: 0.5\n",
      "Accuracy for column DopaDefic: 0.66\n",
      "Accuracy for column Education: 0.56\n",
      "Accuracy for column Epworth: 0.7\n",
      "Accuracy for column Fatigue: 0.6\n",
      "Accuracy for column Geriatric_Depression: 0.6\n",
      "Accuracy for column Hallucination: 0.7\n",
      "Accuracy for column Hand: 0.56\n",
      "Accuracy for column Hopkins: 0.72\n",
      "Accuracy for column Hopkins_Recog: 0.7\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.62\n",
      "Accuracy for column Impulsive_ICD: 0.74\n",
      "Accuracy for column LetterNumber: 0.56\n",
      "Accuracy for column Lexical_Fluency: 0.7\n",
      "Accuracy for column LightHead: 0.42\n",
      "Accuracy for column Modif_Boston: 0.76\n",
      "Accuracy for column Montreal_Cognitive: 0.58\n",
      "Accuracy for column Pain: 0.7\n",
      "Accuracy for column REM_AwakeDream: 0.76\n",
      "Accuracy for column REM_AwakeProblem: 0.64\n",
      "Accuracy for column REM_Dream: 0.7\n",
      "Accuracy for column REM_Movement: 0.72\n",
      "Accuracy for column SCOPA_Cardio: 0.44\n",
      "Accuracy for column SCOPA_Eye: 0.66\n",
      "Accuracy for column SCOPA_Gastro: 0.54\n",
      "Accuracy for column SCOPA_Sex: 0.64\n",
      "Accuracy for column SCOPA_Thermo: 0.62\n",
      "Accuracy for column SCOPA_Urine: 0.74\n",
      "Accuracy for column Semantic: 0.6\n",
      "Accuracy for column SleepDay: 0.52\n",
      "Accuracy for column SleepNight: 0.76\n",
      "Accuracy for column STAIA: 0.58\n",
      "Accuracy for column STAIS: 0.68\n",
      "Accuracy for column Symbol_Digit: 0.74\n",
      "Accuracy for column Trail_Making_A: 0.66\n",
      "Accuracy for column Trail_Making_B: 0.62\n",
      "Accuracy for column UPSIT: 0.86\n",
      "Accuracy for column Urine: 0.42\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        nb_model = GaussianNB()\n",
    "        nb_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = nb_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_NaiveBased.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(nb_model, f\"{col}_NaiveBased_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f84924",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd71892f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T06:22:45.720188Z",
     "start_time": "2023-02-15T06:22:20.554907Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 2\n",
      "Mean accuracy: 0.796\n",
      "Run 3\n",
      "Mean accuracy: 0.796\n",
      "Run 4\n",
      "Mean accuracy: 0.808\n",
      "Run 5\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 6\n",
      "Mean accuracy: 0.792\n",
      "Run 7\n",
      "Mean accuracy: 0.792\n",
      "Run 8\n",
      "Mean accuracy: 0.792\n",
      "Run 9\n",
      "Mean accuracy: 0.804\n",
      "Run 10\n",
      "Mean accuracy: 0.784\n",
      "Run 11\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 12\n",
      "Mean accuracy: 0.8200000000000001\n",
      "Run 13\n",
      "Mean accuracy: 0.8\n",
      "Run 14\n",
      "Mean accuracy: 0.8440000000000001\n",
      "Run 15\n",
      "Mean accuracy: 0.808\n",
      "Run 16\n",
      "Mean accuracy: 0.8560000000000001\n",
      "Run 17\n",
      "Mean accuracy: 0.828\n",
      "Run 18\n",
      "Mean accuracy: 0.8360000000000001\n",
      "Run 19\n",
      "Mean accuracy: 0.8240000000000001\n",
      "Run 20\n",
      "Mean accuracy: 0.78\n",
      "Run 21\n",
      "Mean accuracy: 0.788\n",
      "Run 22\n",
      "Mean accuracy: 0.8240000000000001\n",
      "Run 23\n",
      "Mean accuracy: 0.796\n",
      "Run 24\n",
      "Mean accuracy: 0.8200000000000001\n",
      "Run 25\n",
      "Mean accuracy: 0.812\n",
      "Run 26\n",
      "Mean accuracy: 0.808\n",
      "Run 27\n",
      "Mean accuracy: 0.7999999999999999\n",
      "Run 28\n",
      "Mean accuracy: 0.808\n",
      "Run 29\n",
      "Mean accuracy: 0.8240000000000001\n",
      "Run 30\n",
      "Mean accuracy: 0.8280000000000001\n",
      "Run 31\n",
      "Mean accuracy: 0.808\n",
      "Run 32\n",
      "Mean accuracy: 0.768\n",
      "Run 33\n",
      "Mean accuracy: 0.804\n",
      "Run 34\n",
      "Mean accuracy: 0.784\n",
      "Run 35\n",
      "Mean accuracy: 0.776\n",
      "Run 36\n",
      "Mean accuracy: 0.78\n",
      "Run 37\n",
      "Mean accuracy: 0.796\n",
      "Run 38\n",
      "Mean accuracy: 0.812\n",
      "Run 39\n",
      "Mean accuracy: 0.784\n",
      "Run 40\n",
      "Mean accuracy: 0.812\n",
      "Run 41\n",
      "Mean accuracy: 0.828\n",
      "Run 42\n",
      "Mean accuracy: 0.78\n",
      "Run 43\n",
      "Mean accuracy: 0.8200000000000001\n",
      "Run 44\n",
      "Mean accuracy: 0.792\n",
      "Run 45\n",
      "Mean accuracy: 0.8240000000000001\n",
      "Run 46\n",
      "Mean accuracy: 0.796\n",
      "Run 47\n",
      "Mean accuracy: 0.804\n",
      "Run 48\n",
      "Mean accuracy: 0.808\n",
      "Run 49\n",
      "Mean accuracy: 0.8200000000000001\n",
      "Run 50\n",
      "Mean accuracy: 0.8240000000000001\n",
      "Run 51\n",
      "Mean accuracy: 0.808\n",
      "Run 52\n",
      "Mean accuracy: 0.804\n",
      "Run 53\n",
      "Mean accuracy: 0.804\n",
      "Run 54\n",
      "Mean accuracy: 0.8\n",
      "Run 55\n",
      "Mean accuracy: 0.812\n",
      "Run 56\n",
      "Mean accuracy: 0.804\n",
      "Run 57\n",
      "Mean accuracy: 0.8\n",
      "Run 58\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 59\n",
      "Mean accuracy: 0.788\n",
      "Run 60\n",
      "Mean accuracy: 0.8280000000000001\n",
      "Run 61\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 62\n",
      "Mean accuracy: 0.796\n",
      "Run 63\n",
      "Mean accuracy: 0.808\n",
      "Run 64\n",
      "Mean accuracy: 0.792\n",
      "Run 65\n",
      "Mean accuracy: 0.772\n",
      "Run 66\n",
      "Mean accuracy: 0.808\n",
      "Run 67\n",
      "Mean accuracy: 0.796\n",
      "Run 68\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 69\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 70\n",
      "Mean accuracy: 0.776\n",
      "Run 71\n",
      "Mean accuracy: 0.7919999999999999\n",
      "Run 72\n",
      "Mean accuracy: 0.804\n",
      "Run 73\n",
      "Mean accuracy: 0.808\n",
      "Run 74\n",
      "Mean accuracy: 0.808\n",
      "Run 75\n",
      "Mean accuracy: 0.808\n",
      "Run 76\n",
      "Mean accuracy: 0.784\n",
      "Run 77\n",
      "Mean accuracy: 0.808\n",
      "Run 78\n",
      "Mean accuracy: 0.808\n",
      "Run 79\n",
      "Mean accuracy: 0.8\n",
      "Run 80\n",
      "Mean accuracy: 0.8\n",
      "Run 81\n",
      "Mean accuracy: 0.764\n",
      "Run 82\n",
      "Mean accuracy: 0.772\n",
      "Run 83\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 84\n",
      "Mean accuracy: 0.8160000000000001\n",
      "Run 85\n",
      "Mean accuracy: 0.784\n",
      "Run 86\n",
      "Mean accuracy: 0.7999999999999999\n",
      "Run 87\n",
      "Mean accuracy: 0.836\n",
      "Run 88\n",
      "Mean accuracy: 0.812\n",
      "Run 89\n",
      "Mean accuracy: 0.808\n",
      "Run 90\n",
      "Mean accuracy: 0.792\n",
      "Run 91\n",
      "Mean accuracy: 0.812\n",
      "Run 92\n",
      "Mean accuracy: 0.812\n",
      "Run 93\n",
      "Mean accuracy: 0.812\n",
      "Run 94\n",
      "Mean accuracy: 0.808\n",
      "Run 95\n",
      "Mean accuracy: 0.796\n",
      "Run 96\n",
      "Mean accuracy: 0.8\n",
      "Run 97\n",
      "Mean accuracy: 0.8240000000000001\n",
      "Run 98\n",
      "Mean accuracy: 0.8400000000000001\n",
      "Run 99\n",
      "Mean accuracy: 0.8320000000000001\n",
      "Run 100\n",
      "Mean accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(f'Run {i}')\n",
    "    data = NonMot1.drop('APPRDX', axis=1)\n",
    "    labels = NonMot1['APPRDX']\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data, test_data = data.iloc[train_index], data.iloc[test_index]\n",
    "        train_labels, test_labels = labels.iloc[train_index], labels.iloc[test_index]\n",
    "        base_model = DecisionTreeClassifier()\n",
    "        bagging_model = BaggingClassifier(base_estimator=base_model, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "        bagging_model.fit(train_data, train_labels)\n",
    "        predictions = bagging_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(f'Mean accuracy: {mean_accuracy}')\n",
    "    output.append(mean_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100bagging.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7833be6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T10:37:59.643066Z",
     "start_time": "2023-02-25T10:37:51.215937Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.6559999999999999\n",
      "Accuracy for column Apathy: 0.6559999999999999\n",
      "Accuracy for column Benton: 0.572\n",
      "Accuracy for column Clock: 0.636\n",
      "Accuracy for column Cognition: 0.6559999999999999\n",
      "Accuracy for column COGSTATE: 0.6559999999999999\n",
      "Accuracy for column Constipate: 0.6559999999999999\n",
      "Accuracy for column Depress: 0.6559999999999999\n",
      "Accuracy for column DopaDefic: 0.6479999999999999\n",
      "Accuracy for column Education: 0.6279999999999999\n",
      "Accuracy for column Epworth: 0.6479999999999999\n",
      "Accuracy for column Fatigue: 0.624\n",
      "Accuracy for column Geriatric_Depression: 0.6439999999999999\n",
      "Accuracy for column Hallucination: 0.6479999999999999\n",
      "Accuracy for column Hand: 0.6559999999999999\n",
      "Accuracy for column Hopkins: 0.6359999999999999\n",
      "Accuracy for column Hopkins_Recog: 0.6359999999999999\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.64\n",
      "Accuracy for column Impulsive_ICD: 0.6519999999999999\n",
      "Accuracy for column LetterNumber: 0.612\n",
      "Accuracy for column Lexical_Fluency: 0.5720000000000001\n",
      "Accuracy for column LightHead: 0.6559999999999999\n",
      "Accuracy for column Modif_Boston: 0.5599999999999999\n",
      "Accuracy for column Montreal_Cognitive: 0.688\n",
      "Accuracy for column Pain: 0.6559999999999999\n",
      "Accuracy for column REM_AwakeDream: 0.6559999999999999\n",
      "Accuracy for column REM_AwakeProblem: 0.6559999999999999\n",
      "Accuracy for column REM_Dream: 0.6559999999999999\n",
      "Accuracy for column REM_Movement: 0.6479999999999999\n",
      "Accuracy for column SCOPA_Cardio: 0.6559999999999999\n",
      "Accuracy for column SCOPA_Eye: 0.6559999999999999\n",
      "Accuracy for column SCOPA_Gastro: 0.6399999999999999\n",
      "Accuracy for column SCOPA_Sex: 0.6559999999999999\n",
      "Accuracy for column SCOPA_Thermo: 0.6559999999999999\n",
      "Accuracy for column SCOPA_Urine: 0.6479999999999999\n",
      "Accuracy for column Semantic: 0.592\n",
      "Accuracy for column SleepDay: 0.6559999999999999\n",
      "Accuracy for column SleepNight: 0.6559999999999999\n",
      "Accuracy for column STAIA: 0.6399999999999999\n",
      "Accuracy for column STAIS: 0.608\n",
      "Accuracy for column Symbol_Digit: 0.6839999999999999\n",
      "Accuracy for column Trail_Making_A: 0.6\n",
      "Accuracy for column Trail_Making_B: 0.616\n",
      "Accuracy for column UPSIT: 0.804\n",
      "Accuracy for column Urine: 0.6519999999999999\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        X = NonMot1[[col]]\n",
    "        y = NonMot1['APPRDX']\n",
    "        \n",
    "        base_model = DecisionTreeClassifier()\n",
    "        bagging_model = BaggingClassifier(base_estimator=base_model, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "        bagging_model.fit(X,y)\n",
    "        # 10-fold cross-validation\n",
    "        scores = cross_val_score(bagging_model, X, y, cv=10)\n",
    "        print(f'Accuracy for column {col}: {np.mean(scores)}')\n",
    "        output.append(np.mean(scores))\n",
    "\n",
    "        np.savetxt(f\"{col}_Bag.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(bagging_model, f\"{col}_bag_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a281b",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "926e7d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T06:24:48.908103Z",
     "start_time": "2023-02-15T06:24:43.293875Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.764\n",
      "2\n",
      "Accuracy: 0.732\n",
      "3\n",
      "Accuracy: 0.74\n",
      "4\n",
      "Accuracy: 0.736\n",
      "5\n",
      "Accuracy: 0.748\n",
      "6\n",
      "Accuracy: 0.76\n",
      "7\n",
      "Accuracy: 0.74\n",
      "8\n",
      "Accuracy: 0.756\n",
      "9\n",
      "Accuracy: 0.752\n",
      "10\n",
      "Accuracy: 0.748\n",
      "11\n",
      "Accuracy: 0.748\n",
      "12\n",
      "Accuracy: 0.756\n",
      "13\n",
      "Accuracy: 0.732\n",
      "14\n",
      "Accuracy: 0.756\n",
      "15\n",
      "Accuracy: 0.732\n",
      "16\n",
      "Accuracy: 0.732\n",
      "17\n",
      "Accuracy: 0.752\n",
      "18\n",
      "Accuracy: 0.736\n",
      "19\n",
      "Accuracy: 0.748\n",
      "20\n",
      "Accuracy: 0.732\n",
      "21\n",
      "Accuracy: 0.752\n",
      "22\n",
      "Accuracy: 0.768\n",
      "23\n",
      "Accuracy: 0.752\n",
      "24\n",
      "Accuracy: 0.732\n",
      "25\n",
      "Accuracy: 0.732\n",
      "26\n",
      "Accuracy: 0.748\n",
      "27\n",
      "Accuracy: 0.736\n",
      "28\n",
      "Accuracy: 0.728\n",
      "29\n",
      "Accuracy: 0.728\n",
      "30\n",
      "Accuracy: 0.756\n",
      "31\n",
      "Accuracy: 0.748\n",
      "32\n",
      "Accuracy: 0.748\n",
      "33\n",
      "Accuracy: 0.744\n",
      "34\n",
      "Accuracy: 0.752\n",
      "35\n",
      "Accuracy: 0.752\n",
      "36\n",
      "Accuracy: 0.744\n",
      "37\n",
      "Accuracy: 0.768\n",
      "38\n",
      "Accuracy: 0.728\n",
      "39\n",
      "Accuracy: 0.728\n",
      "40\n",
      "Accuracy: 0.744\n",
      "41\n",
      "Accuracy: 0.74\n",
      "42\n",
      "Accuracy: 0.748\n",
      "43\n",
      "Accuracy: 0.732\n",
      "44\n",
      "Accuracy: 0.748\n",
      "45\n",
      "Accuracy: 0.736\n",
      "46\n",
      "Accuracy: 0.748\n",
      "47\n",
      "Accuracy: 0.752\n",
      "48\n",
      "Accuracy: 0.756\n",
      "49\n",
      "Accuracy: 0.74\n",
      "50\n",
      "Accuracy: 0.732\n",
      "51\n",
      "Accuracy: 0.74\n",
      "52\n",
      "Accuracy: 0.736\n",
      "53\n",
      "Accuracy: 0.744\n",
      "54\n",
      "Accuracy: 0.732\n",
      "55\n",
      "Accuracy: 0.76\n",
      "56\n",
      "Accuracy: 0.72\n",
      "57\n",
      "Accuracy: 0.736\n",
      "58\n",
      "Accuracy: 0.728\n",
      "59\n",
      "Accuracy: 0.776\n",
      "60\n",
      "Accuracy: 0.748\n",
      "61\n",
      "Accuracy: 0.764\n",
      "62\n",
      "Accuracy: 0.756\n",
      "63\n",
      "Accuracy: 0.756\n",
      "64\n",
      "Accuracy: 0.732\n",
      "65\n",
      "Accuracy: 0.752\n",
      "66\n",
      "Accuracy: 0.78\n",
      "67\n",
      "Accuracy: 0.748\n",
      "68\n",
      "Accuracy: 0.78\n",
      "69\n",
      "Accuracy: 0.752\n",
      "70\n",
      "Accuracy: 0.76\n",
      "71\n",
      "Accuracy: 0.764\n",
      "72\n",
      "Accuracy: 0.728\n",
      "73\n",
      "Accuracy: 0.736\n",
      "74\n",
      "Accuracy: 0.736\n",
      "75\n",
      "Accuracy: 0.748\n",
      "76\n",
      "Accuracy: 0.768\n",
      "77\n",
      "Accuracy: 0.724\n",
      "78\n",
      "Accuracy: 0.728\n",
      "79\n",
      "Accuracy: 0.752\n",
      "80\n",
      "Accuracy: 0.72\n",
      "81\n",
      "Accuracy: 0.744\n",
      "82\n",
      "Accuracy: 0.744\n",
      "83\n",
      "Accuracy: 0.764\n",
      "84\n",
      "Accuracy: 0.744\n",
      "85\n",
      "Accuracy: 0.724\n",
      "86\n",
      "Accuracy: 0.748\n",
      "87\n",
      "Accuracy: 0.708\n",
      "88\n",
      "Accuracy: 0.736\n",
      "89\n",
      "Accuracy: 0.744\n",
      "90\n",
      "Accuracy: 0.744\n",
      "91\n",
      "Accuracy: 0.752\n",
      "92\n",
      "Accuracy: 0.744\n",
      "93\n",
      "Accuracy: 0.716\n",
      "94\n",
      "Accuracy: 0.748\n",
      "95\n",
      "Accuracy: 0.736\n",
      "96\n",
      "Accuracy: 0.76\n",
      "97\n",
      "Accuracy: 0.76\n",
      "98\n",
      "Accuracy: 0.736\n",
      "99\n",
      "Accuracy: 0.732\n",
      "100\n",
      "Accuracy: 0.748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    data = NonMot1.drop('APPRDX', axis=1)\n",
    "    labels = NonMot1['APPRDX']\n",
    "    \n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    accuracy_scores = cross_val_score(dt_model, data, labels, cv=10)\n",
    "    \n",
    "    mean_accuracy = accuracy_scores.mean()\n",
    "    print(f'Accuracy: {mean_accuracy}')\n",
    "    output.append(mean_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100DecisionTree.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0de657",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:13.601888Z",
     "start_time": "2023-02-15T04:52:13.285502Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.66\n",
      "Accuracy for column Apathy: 0.74\n",
      "Accuracy for column Benton: 0.56\n",
      "Accuracy for column Clock: 0.64\n",
      "Accuracy for column Cognition: 0.6\n",
      "Accuracy for column COGSTATE: 0.56\n",
      "Accuracy for column Constipate: 0.64\n",
      "Accuracy for column Depress: 0.54\n",
      "Accuracy for column DopaDefic: 0.64\n",
      "Accuracy for column Education: 0.54\n",
      "Accuracy for column Epworth: 0.62\n",
      "Accuracy for column Fatigue: 0.5\n",
      "Accuracy for column Geriatric_Depression: 0.62\n",
      "Accuracy for column Hallucination: 0.66\n",
      "Accuracy for column Hand: 0.5\n",
      "Accuracy for column Hopkins: 0.54\n",
      "Accuracy for column Hopkins_Recog: 0.48\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.62\n",
      "Accuracy for column Impulsive_ICD: 0.62\n",
      "Accuracy for column LetterNumber: 0.66\n",
      "Accuracy for column Lexical_Fluency: 0.5\n",
      "Accuracy for column LightHead: 0.6\n",
      "Accuracy for column Modif_Boston: 0.5\n",
      "Accuracy for column Montreal_Cognitive: 0.6\n",
      "Accuracy for column Pain: 0.64\n",
      "Accuracy for column REM_AwakeDream: 0.74\n",
      "Accuracy for column REM_AwakeProblem: 0.62\n",
      "Accuracy for column REM_Dream: 0.6\n",
      "Accuracy for column REM_Movement: 0.58\n",
      "Accuracy for column SCOPA_Cardio: 0.64\n",
      "Accuracy for column SCOPA_Eye: 0.64\n",
      "Accuracy for column SCOPA_Gastro: 0.62\n",
      "Accuracy for column SCOPA_Sex: 0.66\n",
      "Accuracy for column SCOPA_Thermo: 0.74\n",
      "Accuracy for column SCOPA_Urine: 0.62\n",
      "Accuracy for column Semantic: 0.6\n",
      "Accuracy for column SleepDay: 0.64\n",
      "Accuracy for column SleepNight: 0.74\n",
      "Accuracy for column STAIA: 0.62\n",
      "Accuracy for column STAIS: 0.54\n",
      "Accuracy for column Symbol_Digit: 0.7\n",
      "Accuracy for column Trail_Making_A: 0.66\n",
      "Accuracy for column Trail_Making_B: 0.58\n",
      "Accuracy for column UPSIT: 0.84\n",
      "Accuracy for column Urine: 0.66\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        dt_model = DecisionTreeClassifier()\n",
    "        dt_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = dt_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_DecTree.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(dt_model, f\"{col}_DecTree_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0eac81",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b36aafc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:50:28.354812Z",
     "start_time": "2023-02-15T05:48:14.498687Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Mean accuracy: 0.8200000000000001\n",
      "2\n",
      "Mean accuracy: 0.8160000000000001\n",
      "3\n",
      "Mean accuracy: 0.8240000000000001\n",
      "4\n",
      "Mean accuracy: 0.8240000000000001\n",
      "5\n",
      "Mean accuracy: 0.8160000000000001\n",
      "6\n",
      "Mean accuracy: 0.8240000000000001\n",
      "7\n",
      "Mean accuracy: 0.8320000000000001\n",
      "8\n",
      "Mean accuracy: 0.808\n",
      "9\n",
      "Mean accuracy: 0.8160000000000001\n",
      "10\n",
      "Mean accuracy: 0.8240000000000001\n",
      "11\n",
      "Mean accuracy: 0.8360000000000001\n",
      "12\n",
      "Mean accuracy: 0.8280000000000001\n",
      "13\n",
      "Mean accuracy: 0.8360000000000001\n",
      "14\n",
      "Mean accuracy: 0.8240000000000001\n",
      "15\n",
      "Mean accuracy: 0.8160000000000001\n",
      "16\n",
      "Mean accuracy: 0.8240000000000001\n",
      "17\n",
      "Mean accuracy: 0.8320000000000001\n",
      "18\n",
      "Mean accuracy: 0.8200000000000001\n",
      "19\n",
      "Mean accuracy: 0.8160000000000001\n",
      "20\n",
      "Mean accuracy: 0.8360000000000001\n",
      "21\n",
      "Mean accuracy: 0.808\n",
      "22\n",
      "Mean accuracy: 0.8320000000000001\n",
      "23\n",
      "Mean accuracy: 0.8240000000000001\n",
      "24\n",
      "Mean accuracy: 0.8200000000000001\n",
      "25\n",
      "Mean accuracy: 0.8240000000000001\n",
      "26\n",
      "Mean accuracy: 0.8240000000000001\n",
      "27\n",
      "Mean accuracy: 0.8360000000000001\n",
      "28\n",
      "Mean accuracy: 0.8160000000000001\n",
      "29\n",
      "Mean accuracy: 0.812\n",
      "30\n",
      "Mean accuracy: 0.8160000000000001\n",
      "31\n",
      "Mean accuracy: 0.8240000000000001\n",
      "32\n",
      "Mean accuracy: 0.8320000000000001\n",
      "33\n",
      "Mean accuracy: 0.8320000000000001\n",
      "34\n",
      "Mean accuracy: 0.8280000000000001\n",
      "35\n",
      "Mean accuracy: 0.8200000000000001\n",
      "36\n",
      "Mean accuracy: 0.796\n",
      "37\n",
      "Mean accuracy: 0.8320000000000001\n",
      "38\n",
      "Mean accuracy: 0.8240000000000001\n",
      "39\n",
      "Mean accuracy: 0.8320000000000001\n",
      "40\n",
      "Mean accuracy: 0.8240000000000001\n",
      "41\n",
      "Mean accuracy: 0.8160000000000001\n",
      "42\n",
      "Mean accuracy: 0.8240000000000001\n",
      "43\n",
      "Mean accuracy: 0.8320000000000001\n",
      "44\n",
      "Mean accuracy: 0.804\n",
      "45\n",
      "Mean accuracy: 0.812\n",
      "46\n",
      "Mean accuracy: 0.8360000000000001\n",
      "47\n",
      "Mean accuracy: 0.8240000000000001\n",
      "48\n",
      "Mean accuracy: 0.812\n",
      "49\n",
      "Mean accuracy: 0.8200000000000001\n",
      "50\n",
      "Mean accuracy: 0.8280000000000001\n",
      "51\n",
      "Mean accuracy: 0.8200000000000001\n",
      "52\n",
      "Mean accuracy: 0.812\n",
      "53\n",
      "Mean accuracy: 0.8200000000000001\n",
      "54\n",
      "Mean accuracy: 0.8320000000000001\n",
      "55\n",
      "Mean accuracy: 0.808\n",
      "56\n",
      "Mean accuracy: 0.808\n",
      "57\n",
      "Mean accuracy: 0.8200000000000001\n",
      "58\n",
      "Mean accuracy: 0.808\n",
      "59\n",
      "Mean accuracy: 0.8200000000000001\n",
      "60\n",
      "Mean accuracy: 0.8240000000000001\n",
      "61\n",
      "Mean accuracy: 0.8200000000000001\n",
      "62\n",
      "Mean accuracy: 0.8280000000000001\n",
      "63\n",
      "Mean accuracy: 0.844\n",
      "64\n",
      "Mean accuracy: 0.8240000000000001\n",
      "65\n",
      "Mean accuracy: 0.812\n",
      "66\n",
      "Mean accuracy: 0.8320000000000001\n",
      "67\n",
      "Mean accuracy: 0.8360000000000001\n",
      "68\n",
      "Mean accuracy: 0.812\n",
      "69\n",
      "Mean accuracy: 0.8400000000000001\n",
      "70\n",
      "Mean accuracy: 0.792\n",
      "71\n",
      "Mean accuracy: 0.8400000000000001\n",
      "72\n",
      "Mean accuracy: 0.8160000000000001\n",
      "73\n",
      "Mean accuracy: 0.8240000000000001\n",
      "74\n",
      "Mean accuracy: 0.804\n",
      "75\n",
      "Mean accuracy: 0.8240000000000001\n",
      "76\n",
      "Mean accuracy: 0.8200000000000001\n",
      "77\n",
      "Mean accuracy: 0.8320000000000001\n",
      "78\n",
      "Mean accuracy: 0.8200000000000001\n",
      "79\n",
      "Mean accuracy: 0.8280000000000001\n",
      "80\n",
      "Mean accuracy: 0.8280000000000001\n",
      "81\n",
      "Mean accuracy: 0.8240000000000001\n",
      "82\n",
      "Mean accuracy: 0.82\n",
      "83\n",
      "Mean accuracy: 0.8320000000000001\n",
      "84\n",
      "Mean accuracy: 0.8200000000000001\n",
      "85\n",
      "Mean accuracy: 0.812\n",
      "86\n",
      "Mean accuracy: 0.8200000000000001\n",
      "87\n",
      "Mean accuracy: 0.8160000000000001\n",
      "88\n",
      "Mean accuracy: 0.8280000000000001\n",
      "89\n",
      "Mean accuracy: 0.812\n",
      "90\n",
      "Mean accuracy: 0.8160000000000001\n",
      "91\n",
      "Mean accuracy: 0.808\n",
      "92\n",
      "Mean accuracy: 0.8200000000000001\n",
      "93\n",
      "Mean accuracy: 0.808\n",
      "94\n",
      "Mean accuracy: 0.8280000000000001\n",
      "95\n",
      "Mean accuracy: 0.812\n",
      "96\n",
      "Mean accuracy: 0.8160000000000001\n",
      "97\n",
      "Mean accuracy: 0.8360000000000001\n",
      "98\n",
      "Mean accuracy: 0.8280000000000001\n",
      "99\n",
      "Mean accuracy: 0.8400000000000001\n",
      "100\n",
      "Mean accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    random_forest_model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "    scores = cross_val_score(random_forest_model, X, y, cv=10)\n",
    "    mean_score = scores.mean()\n",
    "    print(f'Mean accuracy: {mean_score}')\n",
    "    output.append(mean_score)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100RandomForest_10CV.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633c3099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:52:48.335417Z",
     "start_time": "2023-02-15T04:52:41.214586Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.62\n",
      "Accuracy for column Apathy: 0.64\n",
      "Accuracy for column Benton: 0.64\n",
      "Accuracy for column Clock: 0.56\n",
      "Accuracy for column Cognition: 0.68\n",
      "Accuracy for column COGSTATE: 0.8\n",
      "Accuracy for column Constipate: 0.62\n",
      "Accuracy for column Depress: 0.58\n",
      "Accuracy for column DopaDefic: 0.72\n",
      "Accuracy for column Education: 0.62\n",
      "Accuracy for column Epworth: 0.58\n",
      "Accuracy for column Fatigue: 0.58\n",
      "Accuracy for column Geriatric_Depression: 0.66\n",
      "Accuracy for column Hallucination: 0.64\n",
      "Accuracy for column Hand: 0.52\n",
      "Accuracy for column Hopkins: 0.7\n",
      "Accuracy for column Hopkins_Recog: 0.58\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.64\n",
      "Accuracy for column Impulsive_ICD: 0.84\n",
      "Accuracy for column LetterNumber: 0.66\n",
      "Accuracy for column Lexical_Fluency: 0.6\n",
      "Accuracy for column LightHead: 0.64\n",
      "Accuracy for column Modif_Boston: 0.68\n",
      "Accuracy for column Montreal_Cognitive: 0.68\n",
      "Accuracy for column Pain: 0.66\n",
      "Accuracy for column REM_AwakeDream: 0.62\n",
      "Accuracy for column REM_AwakeProblem: 0.54\n",
      "Accuracy for column REM_Dream: 0.64\n",
      "Accuracy for column REM_Movement: 0.62\n",
      "Accuracy for column SCOPA_Cardio: 0.66\n",
      "Accuracy for column SCOPA_Eye: 0.72\n",
      "Accuracy for column SCOPA_Gastro: 0.56\n",
      "Accuracy for column SCOPA_Sex: 0.62\n",
      "Accuracy for column SCOPA_Thermo: 0.78\n",
      "Accuracy for column SCOPA_Urine: 0.68\n",
      "Accuracy for column Semantic: 0.64\n",
      "Accuracy for column SleepDay: 0.76\n",
      "Accuracy for column SleepNight: 0.7\n",
      "Accuracy for column STAIA: 0.64\n",
      "Accuracy for column STAIS: 0.8\n",
      "Accuracy for column Symbol_Digit: 0.66\n",
      "Accuracy for column Trail_Making_A: 0.58\n",
      "Accuracy for column Trail_Making_B: 0.7\n",
      "Accuracy for column UPSIT: 0.86\n",
      "Accuracy for column Urine: 0.6\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        random_forest_model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "        random_forest_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = random_forest_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_RF.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(random_forest_model, f\"{col}_RF_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba1308",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e276083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T06:56:27.557385Z",
     "start_time": "2023-02-15T06:32:17.341831Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "2\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "3\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "4\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "5\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "6\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "7\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "8\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "9\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "10\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "11\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "12\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "13\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "14\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "15\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.66\n",
      "16\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "17\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "18\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "19\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "20\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "21\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.88\n",
      "22\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "23\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "24\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "25\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.9\n",
      "26\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "27\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "28\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "29\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "30\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "31\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "32\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "33\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "34\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "35\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "36\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "37\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "38\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "39\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "40\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "41\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.88\n",
      "42\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "43\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "44\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.7\n",
      "45\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "46\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "47\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "48\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "49\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "50\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "51\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "52\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.7\n",
      "53\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "54\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "55\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "56\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "57\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "58\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "59\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "60\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "61\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "62\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "63\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "64\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "65\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "66\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "67\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "68\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "69\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "70\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "71\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "72\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "73\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "74\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.74\n",
      "75\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "76\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "77\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "78\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.88\n",
      "79\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "80\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "81\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "82\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "83\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "84\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.72\n",
      "85\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "86\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.66\n",
      "87\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "88\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "89\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "90\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "91\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "92\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "93\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.84\n",
      "94\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "95\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.8\n",
      "96\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.82\n",
      "97\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.76\n",
      "98\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.86\n",
      "99\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.78\n",
      "100\n",
      "Mean cross-validation accuracy: 0.8\n",
      "Test accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    lasso_model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=500)\n",
    "    parameters = {'C': [0.1, 1, 10, 100]}\n",
    "    lasso_model = GridSearchCV(lasso_model, parameters)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    \n",
    "    cv_scores = cross_val_score(lasso_model, X, y, cv=10)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    print(f'Mean cross-validation accuracy: {mean_cv_score}')\n",
    "    \n",
    "    predictions = lasso_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100Lasso.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e7c57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:26:45.114975Z",
     "start_time": "2023-02-15T05:26:45.114975Z"
    }
   },
   "source": [
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    lasso_model = LogisticRegression(penalty='l1', solver = 'liblinear', max_iter = 500)\n",
    "    parameters = {'C': [0.1, 1, 10, 100]}\n",
    "    lasso_model = GridSearchCV(lasso_model, parameters)\n",
    "    lasso_model.fit(train_data, train_labels)\n",
    "\n",
    "    \n",
    "    predictions = lasso_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100Lasso.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6c8017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:19:18.570299Z",
     "start_time": "2023-02-25T08:19:15.345508Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.64\n",
      "Accuracy for column Apathy: 0.7\n",
      "Accuracy for column Benton: 0.56\n",
      "Accuracy for column Clock: 0.72\n",
      "Accuracy for column Cognition: 0.54\n",
      "Accuracy for column COGSTATE: 0.6\n",
      "Accuracy for column Constipate: 0.76\n",
      "Accuracy for column Depress: 0.82\n",
      "Accuracy for column DopaDefic: 0.8\n",
      "Accuracy for column Education: 0.68\n",
      "Accuracy for column Epworth: 0.62\n",
      "Accuracy for column Fatigue: 0.66\n",
      "Accuracy for column Geriatric_Depression: 0.78\n",
      "Accuracy for column Hallucination: 0.6\n",
      "Accuracy for column Hand: 0.58\n",
      "Accuracy for column Hopkins: 0.62\n",
      "Accuracy for column Hopkins_Recog: 0.72\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.62\n",
      "Accuracy for column Impulsive_ICD: 0.64\n",
      "Accuracy for column LetterNumber: 0.68\n",
      "Accuracy for column Lexical_Fluency: 0.62\n",
      "Accuracy for column LightHead: 0.58\n",
      "Accuracy for column Modif_Boston: 0.8\n",
      "Accuracy for column Montreal_Cognitive: 0.7\n",
      "Accuracy for column Pain: 0.58\n",
      "Accuracy for column REM_AwakeDream: 0.62\n",
      "Accuracy for column REM_AwakeProblem: 0.6\n",
      "Accuracy for column REM_Dream: 0.68\n",
      "Accuracy for column REM_Movement: 0.76\n",
      "Accuracy for column SCOPA_Cardio: 0.68\n",
      "Accuracy for column SCOPA_Eye: 0.66\n",
      "Accuracy for column SCOPA_Gastro: 0.66\n",
      "Accuracy for column SCOPA_Sex: 0.7\n",
      "Accuracy for column SCOPA_Thermo: 0.68\n",
      "Accuracy for column SCOPA_Urine: 0.74\n",
      "Accuracy for column Semantic: 0.72\n",
      "Accuracy for column SleepDay: 0.62\n",
      "Accuracy for column SleepNight: 0.58\n",
      "Accuracy for column STAIA: 0.62\n",
      "Accuracy for column STAIS: 0.62\n",
      "Accuracy for column Symbol_Digit: 0.74\n",
      "Accuracy for column Trail_Making_A: 0.6\n",
      "Accuracy for column Trail_Making_B: 0.66\n",
      "Accuracy for column UPSIT: 0.88\n",
      "Accuracy for column Urine: 0.72\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], NonMot1['APPRDX'], \n",
    "                                                                            test_size=0.2)\n",
    "\n",
    "        lasso_model = LogisticRegression(penalty='l1', solver = 'liblinear', max_iter = 1000)\n",
    "        parameters = {'C': [0.1, 1, 10, 100]}\n",
    "        lasso_model = GridSearchCV(lasso_model, parameters)\n",
    "        lasso_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = lasso_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_Lasso.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(lasso_model, f\"{col}_Lasso_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a09d79",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a493eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T11:27:04.197680Z",
     "start_time": "2023-02-15T07:07:42.974489Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "2\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "3\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "4\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "5\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "6\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "7\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "8\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "9\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "10\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "11\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "12\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.88\n",
      "13\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "14\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "15\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "16\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.72\n",
      "17\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "18\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "19\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "20\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "21\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.9\n",
      "22\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "23\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "24\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "25\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.72\n",
      "26\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "27\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "28\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "29\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "30\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "31\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "32\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "33\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "34\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "35\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "36\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.92\n",
      "37\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "38\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "39\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "40\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "41\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "42\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "43\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.88\n",
      "44\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "45\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "46\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "47\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "48\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "49\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "50\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "51\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "52\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "53\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "54\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "55\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "56\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "57\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "58\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "59\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.68\n",
      "60\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.7\n",
      "61\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.88\n",
      "62\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "63\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.88\n",
      "64\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.72\n",
      "65\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.72\n",
      "66\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "67\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "68\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "69\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.76\n",
      "70\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "71\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.92\n",
      "72\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "73\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "74\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "75\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "76\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "77\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "78\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "79\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "80\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.88\n",
      "81\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "82\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "83\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.68\n",
      "84\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "85\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.9\n",
      "86\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "87\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "88\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "89\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "90\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "91\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.72\n",
      "92\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "93\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n",
      "94\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.82\n",
      "95\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.78\n",
      "96\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.86\n",
      "97\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.72\n",
      "98\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.84\n",
      "99\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.74\n",
      "100\n",
      "Mean cross-validation accuracy: 0.772\n",
      "Test accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    enet_model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000, l1_ratio=0.5)\n",
    "    parameters = {'C': [0.1, 1, 10, 100]}\n",
    "    enet_model = GridSearchCV(enet_model, parameters)\n",
    "    enet_model.fit(X_train, y_train)\n",
    "    \n",
    "    cv_scores = cross_val_score(enet_model, X, y, cv=10)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    print(f'Mean cross-validation accuracy: {mean_cv_score}')\n",
    "    \n",
    "    predictions = enet_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "    \n",
    "np.savetxt(\"NonMotor_unCateg_100ElasticNet.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6cea0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:19:54.710417Z",
     "start_time": "2023-02-25T08:19:44.895400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.62\n",
      "Accuracy for column Apathy: 0.6\n",
      "Accuracy for column Benton: 0.62\n",
      "Accuracy for column Clock: 0.64\n",
      "Accuracy for column Cognition: 0.66\n",
      "Accuracy for column COGSTATE: 0.72\n",
      "Accuracy for column Constipate: 0.74\n",
      "Accuracy for column Depress: 0.58\n",
      "Accuracy for column DopaDefic: 0.68\n",
      "Accuracy for column Education: 0.6\n",
      "Accuracy for column Epworth: 0.7\n",
      "Accuracy for column Fatigue: 0.62\n",
      "Accuracy for column Geriatric_Depression: 0.56\n",
      "Accuracy for column Hallucination: 0.64\n",
      "Accuracy for column Hand: 0.66\n",
      "Accuracy for column Hopkins: 0.68\n",
      "Accuracy for column Hopkins_Recog: 0.64\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.68\n",
      "Accuracy for column Impulsive_ICD: 0.66\n",
      "Accuracy for column LetterNumber: 0.56\n",
      "Accuracy for column Lexical_Fluency: 0.66\n",
      "Accuracy for column LightHead: 0.66\n",
      "Accuracy for column Modif_Boston: 0.54\n",
      "Accuracy for column Montreal_Cognitive: 0.66\n",
      "Accuracy for column Pain: 0.64\n",
      "Accuracy for column REM_AwakeDream: 0.74\n",
      "Accuracy for column REM_AwakeProblem: 0.58\n",
      "Accuracy for column REM_Dream: 0.7\n",
      "Accuracy for column REM_Movement: 0.78\n",
      "Accuracy for column SCOPA_Cardio: 0.62\n",
      "Accuracy for column SCOPA_Eye: 0.64\n",
      "Accuracy for column SCOPA_Gastro: 0.66\n",
      "Accuracy for column SCOPA_Sex: 0.62\n",
      "Accuracy for column SCOPA_Thermo: 0.56\n",
      "Accuracy for column SCOPA_Urine: 0.62\n",
      "Accuracy for column Semantic: 0.64\n",
      "Accuracy for column SleepDay: 0.58\n",
      "Accuracy for column SleepNight: 0.52\n",
      "Accuracy for column STAIA: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column STAIS: 0.6\n",
      "Accuracy for column Symbol_Digit: 0.82\n",
      "Accuracy for column Trail_Making_A: 0.66\n",
      "Accuracy for column Trail_Making_B: 0.6\n",
      "Accuracy for column UPSIT: 0.82\n",
      "Accuracy for column Urine: 0.62\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], NonMot1['APPRDX'], \n",
    "                                                                            test_size=0.2)\n",
    "\n",
    "        enet_model = LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10000, l1_ratio=0.5)\n",
    "        parameters = {'C': [0.1, 1, 10, 100]}\n",
    "        enet_model = GridSearchCV(enet_model, parameters)\n",
    "        enet_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = enet_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_enet.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(enet_model, f\"{col}_enet_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc95df22",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4fe2a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T07:07:42.156653Z",
     "start_time": "2023-02-15T06:56:28.423466Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Average accuracy: 0.7879999999999999\n",
      "2\n",
      "Average accuracy: 0.7799999999999999\n",
      "3\n",
      "Average accuracy: 0.7959999999999999\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7999999999999999\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7919999999999999\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.776\n",
      "8\n",
      "Average accuracy: 0.764\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8160000000000001\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7959999999999999\n",
      "11\n",
      "Average accuracy: 0.7879999999999999\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "13\n",
      "Average accuracy: 0.7919999999999999\n",
      "14\n",
      "Average accuracy: 0.7959999999999999\n",
      "15\n",
      "Average accuracy: 0.7839999999999999\n",
      "16\n",
      "Average accuracy: 0.748\n",
      "17\n",
      "Average accuracy: 0.7839999999999999\n",
      "18\n",
      "Average accuracy: 0.7759999999999999\n",
      "19\n",
      "Average accuracy: 0.7719999999999999\n",
      "20\n",
      "Average accuracy: 0.7839999999999999\n",
      "21\n",
      "Average accuracy: 0.7919999999999999\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7959999999999999\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7799999999999998\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7879999999999999\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8160000000000001\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.764\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7759999999999999\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7799999999999999\n",
      "29\n",
      "Average accuracy: 0.7639999999999999\n",
      "30\n",
      "Average accuracy: 0.7919999999999999\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7759999999999999\n",
      "32\n",
      "Average accuracy: 0.7919999999999999\n",
      "33\n",
      "Average accuracy: 0.7959999999999999\n",
      "34\n",
      "Average accuracy: 0.8240000000000001\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7759999999999999\n",
      "36\n",
      "Average accuracy: 0.744\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7879999999999999\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7919999999999999\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "42\n",
      "Average accuracy: 0.7759999999999999\n",
      "43\n",
      "Average accuracy: 0.7959999999999999\n",
      "44\n",
      "Average accuracy: 0.7959999999999999\n",
      "45\n",
      "Average accuracy: 0.7799999999999999\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7879999999999999\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "48\n",
      "Average accuracy: 0.7639999999999999\n",
      "49\n",
      "Average accuracy: 0.8039999999999999\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.808\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.768\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7679999999999999\n",
      "53\n",
      "Average accuracy: 0.7999999999999999\n",
      "54\n",
      "Average accuracy: 0.7599999999999999\n",
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "56\n",
      "Average accuracy: 0.7759999999999999\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "58\n",
      "Average accuracy: 0.756\n",
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "60\n",
      "Average accuracy: 0.76\n",
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7959999999999999\n",
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7919999999999999\n",
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.768\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8039999999999999\n",
      "65\n",
      "Average accuracy: 0.7919999999999999\n",
      "66\n",
      "Average accuracy: 0.7999999999999999\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8039999999999999\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8039999999999999\n",
      "69\n",
      "Average accuracy: 0.8039999999999999\n",
      "70\n",
      "Average accuracy: 0.78\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.8119999999999999\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "73\n",
      "Average accuracy: 0.716\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7759999999999999\n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7879999999999999\n",
      "77\n",
      "Average accuracy: 0.7919999999999999\n",
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7759999999999999\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "80\n",
      "Average accuracy: 0.784\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7799999999999999\n",
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7799999999999999\n",
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7919999999999999\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7759999999999999\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "86\n",
      "Average accuracy: 0.7799999999999999\n",
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7719999999999999\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7799999999999999\n",
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7999999999999999\n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7479999999999999\n",
      "92\n",
      "Average accuracy: 0.8039999999999999\n",
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7679999999999999\n",
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7959999999999999\n",
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7799999999999999\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7839999999999999\n",
      "97\n",
      "Average accuracy: 0.8119999999999999\n",
      "98\n",
      "Average accuracy: 0.7839999999999999\n",
      "99\n",
      "Average accuracy: 0.7799999999999999\n",
      "100\n",
      "Average accuracy: 0.7999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(NonMot1.drop('APPRDX', axis=1), NonMot1['APPRDX']):\n",
    "        train_data, test_data = NonMot1.drop('APPRDX', axis=1).iloc[train_index], NonMot1.drop('APPRDX', axis=1).iloc[test_index]\n",
    "        train_labels, test_labels = NonMot1['APPRDX'].iloc[train_index], NonMot1['APPRDX'].iloc[test_index]\n",
    "\n",
    "        sgd_model = SGDClassifier(loss='log', max_iter=10000)\n",
    "        parameters = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "        sgd_model = GridSearchCV(sgd_model, parameters)\n",
    "        sgd_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = sgd_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracies)/len(accuracies)\n",
    "    print(f'Average accuracy: {avg_accuracy}')\n",
    "    output.append(avg_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100sgd.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c892e3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T04:51:58.679451Z",
     "start_time": "2023-02-15T04:51:47.030916Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.74\n",
      "Accuracy for column Apathy: 0.56\n",
      "Accuracy for column Benton: 0.36\n",
      "Accuracy for column Clock: 0.44\n",
      "Accuracy for column Cognition: 0.56\n",
      "Accuracy for column COGSTATE: 0.6\n",
      "Accuracy for column Constipate: 0.72\n",
      "Accuracy for column Depress: 0.8\n",
      "Accuracy for column DopaDefic: 0.66\n",
      "Accuracy for column Education: 0.78\n",
      "Accuracy for column Epworth: 0.66\n",
      "Accuracy for column Fatigue: 0.58\n",
      "Accuracy for column Geriatric_Depression: 0.7\n",
      "Accuracy for column Hallucination: 0.64\n",
      "Accuracy for column Hand: 0.46\n",
      "Accuracy for column Hopkins: 0.68\n",
      "Accuracy for column Hopkins_Recog: 0.66\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.68\n",
      "Accuracy for column Impulsive_ICD: 0.52\n",
      "Accuracy for column LetterNumber: 0.64\n",
      "Accuracy for column Lexical_Fluency: 0.3\n",
      "Accuracy for column LightHead: 0.66\n",
      "Accuracy for column Modif_Boston: 0.68\n",
      "Accuracy for column Montreal_Cognitive: 0.64\n",
      "Accuracy for column Pain: 0.7\n",
      "Accuracy for column REM_AwakeDream: 0.58\n",
      "Accuracy for column REM_AwakeProblem: 0.64\n",
      "Accuracy for column REM_Dream: 0.66\n",
      "Accuracy for column REM_Movement: 0.68\n",
      "Accuracy for column SCOPA_Cardio: 0.66\n",
      "Accuracy for column SCOPA_Eye: 0.28\n",
      "Accuracy for column SCOPA_Gastro: 0.66\n",
      "Accuracy for column SCOPA_Sex: 0.58\n",
      "Accuracy for column SCOPA_Thermo: 0.72\n",
      "Accuracy for column SCOPA_Urine: 0.68\n",
      "Accuracy for column Semantic: 0.6\n",
      "Accuracy for column SleepDay: 0.58\n",
      "Accuracy for column SleepNight: 0.66\n",
      "Accuracy for column STAIA: 0.72\n",
      "Accuracy for column STAIS: 0.68\n",
      "Accuracy for column Symbol_Digit: 0.64\n",
      "Accuracy for column Trail_Making_A: 0.58\n",
      "Accuracy for column Trail_Making_B: 0.6\n",
      "Accuracy for column UPSIT: 0.84\n",
      "Accuracy for column Urine: 0.28\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        sgd_model = SGDClassifier(loss='log', max_iter=10000)\n",
    "        parameters = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "        sgd_model = GridSearchCV(sgd_model, parameters)\n",
    "        sgd_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = sgd_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_SGD.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(sgd_model, f\"{col}_sgd_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a61e8",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce23ea",
   "metadata": {},
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b2536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T03:42:55.951978Z",
     "start_time": "2023-02-16T03:42:36.342801Z"
    }
   },
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    data = NonMot1.drop('APPRDX', axis=1)\n",
    "    labels = NonMot1['APPRDX']\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    parameters = {'C': [0.01, 0.1, 0.5, 1, 10, 50, 100]}\n",
    "    svm_model = GridSearchCV(svm_model, parameters)\n",
    "    scores = cross_val_score(svm_model, data, labels, cv=10)\n",
    "    accuracy = np.mean(scores)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100svmL.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "055f2ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T05:42:09.186698Z",
     "start_time": "2023-02-16T03:43:04.033729Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.68\n",
      "2\n",
      "Accuracy: 0.82\n",
      "3\n",
      "Accuracy: 0.68\n",
      "4\n",
      "Accuracy: 0.82\n",
      "5\n",
      "Accuracy: 0.72\n",
      "6\n",
      "Accuracy: 0.82\n",
      "7\n",
      "Accuracy: 0.76\n",
      "8\n",
      "Accuracy: 0.74\n",
      "9\n",
      "Accuracy: 0.82\n",
      "10\n",
      "Accuracy: 0.78\n",
      "11\n",
      "Accuracy: 0.84\n",
      "12\n",
      "Accuracy: 0.86\n",
      "13\n",
      "Accuracy: 0.74\n",
      "14\n",
      "Accuracy: 0.82\n",
      "15\n",
      "Accuracy: 0.72\n",
      "16\n",
      "Accuracy: 0.82\n",
      "17\n",
      "Accuracy: 0.7\n",
      "18\n",
      "Accuracy: 0.86\n",
      "19\n",
      "Accuracy: 0.82\n",
      "20\n",
      "Accuracy: 0.78\n",
      "21\n",
      "Accuracy: 0.7\n",
      "22\n",
      "Accuracy: 0.8\n",
      "23\n",
      "Accuracy: 0.78\n",
      "24\n",
      "Accuracy: 0.8\n",
      "25\n",
      "Accuracy: 0.88\n",
      "26\n",
      "Accuracy: 0.82\n",
      "27\n",
      "Accuracy: 0.68\n",
      "28\n",
      "Accuracy: 0.8\n",
      "29\n",
      "Accuracy: 0.78\n",
      "30\n",
      "Accuracy: 0.82\n",
      "31\n",
      "Accuracy: 0.84\n",
      "32\n",
      "Accuracy: 0.86\n",
      "33\n",
      "Accuracy: 0.82\n",
      "34\n",
      "Accuracy: 0.76\n",
      "35\n",
      "Accuracy: 0.84\n",
      "36\n",
      "Accuracy: 0.8\n",
      "37\n",
      "Accuracy: 0.9\n",
      "38\n",
      "Accuracy: 0.76\n",
      "39\n",
      "Accuracy: 0.8\n",
      "40\n",
      "Accuracy: 0.86\n",
      "41\n",
      "Accuracy: 0.8\n",
      "42\n",
      "Accuracy: 0.84\n",
      "43\n",
      "Accuracy: 0.78\n",
      "44\n",
      "Accuracy: 0.74\n",
      "45\n",
      "Accuracy: 0.74\n",
      "46\n",
      "Accuracy: 0.84\n",
      "47\n",
      "Accuracy: 0.8\n",
      "48\n",
      "Accuracy: 0.84\n",
      "49\n",
      "Accuracy: 0.7\n",
      "50\n",
      "Accuracy: 0.82\n",
      "51\n",
      "Accuracy: 0.82\n",
      "52\n",
      "Accuracy: 0.78\n",
      "53\n",
      "Accuracy: 0.78\n",
      "54\n",
      "Accuracy: 0.78\n",
      "55\n",
      "Accuracy: 0.74\n",
      "56\n",
      "Accuracy: 0.68\n",
      "57\n",
      "Accuracy: 0.86\n",
      "58\n",
      "Accuracy: 0.7\n",
      "59\n",
      "Accuracy: 0.74\n",
      "60\n",
      "Accuracy: 0.74\n",
      "61\n",
      "Accuracy: 0.88\n",
      "62\n",
      "Accuracy: 0.82\n",
      "63\n",
      "Accuracy: 0.82\n",
      "64\n",
      "Accuracy: 0.76\n",
      "65\n",
      "Accuracy: 0.82\n",
      "66\n",
      "Accuracy: 0.78\n",
      "67\n",
      "Accuracy: 0.82\n",
      "68\n",
      "Accuracy: 0.76\n",
      "69\n",
      "Accuracy: 0.78\n",
      "70\n",
      "Accuracy: 0.68\n",
      "71\n",
      "Accuracy: 0.86\n",
      "72\n",
      "Accuracy: 0.88\n",
      "73\n",
      "Accuracy: 0.8\n",
      "74\n",
      "Accuracy: 0.84\n",
      "75\n",
      "Accuracy: 0.82\n",
      "76\n",
      "Accuracy: 0.8\n",
      "77\n",
      "Accuracy: 0.84\n",
      "78\n",
      "Accuracy: 0.82\n",
      "79\n",
      "Accuracy: 0.84\n",
      "80\n",
      "Accuracy: 0.84\n",
      "81\n",
      "Accuracy: 0.8\n",
      "82\n",
      "Accuracy: 0.76\n",
      "83\n",
      "Accuracy: 0.8\n",
      "84\n",
      "Accuracy: 0.78\n",
      "85\n",
      "Accuracy: 0.76\n",
      "86\n",
      "Accuracy: 0.76\n",
      "87\n",
      "Accuracy: 0.78\n",
      "88\n",
      "Accuracy: 0.78\n",
      "89\n",
      "Accuracy: 0.84\n",
      "90\n",
      "Accuracy: 0.74\n",
      "91\n",
      "Accuracy: 0.8\n",
      "92\n",
      "Accuracy: 0.8\n",
      "93\n",
      "Accuracy: 0.7\n",
      "94\n",
      "Accuracy: 0.7\n",
      "95\n",
      "Accuracy: 0.84\n",
      "96\n",
      "Accuracy: 0.88\n",
      "97\n",
      "Accuracy: 0.7\n",
      "98\n",
      "Accuracy: 0.8\n",
      "99\n",
      "Accuracy: 0.8\n",
      "100\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    svm_model = SVC(kernel='linear')\n",
    "    parameters = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "    svm_model = GridSearchCV(svm_model, parameters)\n",
    "    svm_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = svm_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100svmL.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ab210",
   "metadata": {},
   "source": [
    "In this line of code, the parameters dictionary is being defined. It contains the hyperparameters for the linear SVM model that will be passed to the GridSearchCV function.\n",
    "\n",
    "The hyperparameter C determines the trade-off between achieving a low training error and a low testing error. In this case, C is set to [1], which means the value of C will be searched for only once, i.e., C=1. C is a regularization parameter, and a smaller value of C will result in a wider margin, while a larger value of C will result in a narrower margin but potentially better classification.\n",
    "\n",
    "    parameters = {'C': [0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "\n",
    "This will test the SVM model with C values of 0.1, 0.5, 1, 5, 10, 50, and 100. The GridSearchCV function will search for the best C value among these values, based on the accuracy of the predictions on the test data.\n",
    "\n",
    "Note that the larger the value of C, the more the model will try to avoid misclassifying any instances in the training set. On the other hand, a smaller value of C will result in a wider margin, and the model will have a higher tolerance for misclassified instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf84abd",
   "metadata": {},
   "source": [
    "### Individual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b80ecd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:20:41.349435Z",
     "start_time": "2023-02-25T08:20:24.979824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.52\n",
      "Accuracy for column Apathy: 0.72\n",
      "Accuracy for column Benton: 0.62\n",
      "Accuracy for column Clock: 0.54\n",
      "Accuracy for column Cognition: 0.56\n",
      "Accuracy for column COGSTATE: 0.7\n",
      "Accuracy for column Constipate: 0.6\n",
      "Accuracy for column Depress: 0.68\n",
      "Accuracy for column DopaDefic: 0.66\n",
      "Accuracy for column Education: 0.64\n",
      "Accuracy for column Epworth: 0.54\n",
      "Accuracy for column Fatigue: 0.62\n",
      "Accuracy for column Geriatric_Depression: 0.58\n",
      "Accuracy for column Hallucination: 0.56\n",
      "Accuracy for column Hand: 0.56\n",
      "Accuracy for column Hopkins: 0.48\n",
      "Accuracy for column Hopkins_Recog: 0.66\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.62\n",
      "Accuracy for column Impulsive_ICD: 0.72\n",
      "Accuracy for column LetterNumber: 0.62\n",
      "Accuracy for column Lexical_Fluency: 0.6\n",
      "Accuracy for column LightHead: 0.58\n",
      "Accuracy for column Modif_Boston: 0.64\n",
      "Accuracy for column Montreal_Cognitive: 0.7\n",
      "Accuracy for column Pain: 0.68\n",
      "Accuracy for column REM_AwakeDream: 0.62\n",
      "Accuracy for column REM_AwakeProblem: 0.6\n",
      "Accuracy for column REM_Dream: 0.68\n",
      "Accuracy for column REM_Movement: 0.62\n",
      "Accuracy for column SCOPA_Cardio: 0.68\n",
      "Accuracy for column SCOPA_Eye: 0.7\n",
      "Accuracy for column SCOPA_Gastro: 0.56\n",
      "Accuracy for column SCOPA_Sex: 0.78\n",
      "Accuracy for column SCOPA_Thermo: 0.56\n",
      "Accuracy for column SCOPA_Urine: 0.66\n",
      "Accuracy for column Semantic: 0.74\n",
      "Accuracy for column SleepDay: 0.7\n",
      "Accuracy for column SleepNight: 0.64\n",
      "Accuracy for column STAIA: 0.48\n",
      "Accuracy for column STAIS: 0.62\n",
      "Accuracy for column Symbol_Digit: 0.74\n",
      "Accuracy for column Trail_Making_A: 0.68\n",
      "Accuracy for column Trail_Making_B: 0.62\n",
      "Accuracy for column UPSIT: 0.84\n",
      "Accuracy for column Urine: 0.58\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        svm_model = SVC(kernel='linear')\n",
    "        parameters = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100]}\n",
    "        svm_model = GridSearchCV(svm_model, parameters)\n",
    "        svm_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = svm_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_svmL.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(svm_model, f\"{col}_svmL_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdf7783",
   "metadata": {},
   "source": [
    "## SVM Radial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a604f44",
   "metadata": {},
   "source": [
    "### All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39faff2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T05:52:39.629674Z",
     "start_time": "2023-02-16T05:50:40.937627Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.56\n",
      "2\n",
      "Accuracy: 0.74\n",
      "3\n",
      "Accuracy: 0.66\n",
      "4\n",
      "Accuracy: 0.76\n",
      "5\n",
      "Accuracy: 0.66\n",
      "6\n",
      "Accuracy: 0.58\n",
      "7\n",
      "Accuracy: 0.68\n",
      "8\n",
      "Accuracy: 0.62\n",
      "9\n",
      "Accuracy: 0.68\n",
      "10\n",
      "Accuracy: 0.68\n",
      "11\n",
      "Accuracy: 0.66\n",
      "12\n",
      "Accuracy: 0.62\n",
      "13\n",
      "Accuracy: 0.66\n",
      "14\n",
      "Accuracy: 0.72\n",
      "15\n",
      "Accuracy: 0.64\n",
      "16\n",
      "Accuracy: 0.64\n",
      "17\n",
      "Accuracy: 0.76\n",
      "18\n",
      "Accuracy: 0.7\n",
      "19\n",
      "Accuracy: 0.6\n",
      "20\n",
      "Accuracy: 0.54\n",
      "21\n",
      "Accuracy: 0.72\n",
      "22\n",
      "Accuracy: 0.54\n",
      "23\n",
      "Accuracy: 0.66\n",
      "24\n",
      "Accuracy: 0.74\n",
      "25\n",
      "Accuracy: 0.62\n",
      "26\n",
      "Accuracy: 0.72\n",
      "27\n",
      "Accuracy: 0.64\n",
      "28\n",
      "Accuracy: 0.66\n",
      "29\n",
      "Accuracy: 0.72\n",
      "30\n",
      "Accuracy: 0.68\n",
      "31\n",
      "Accuracy: 0.62\n",
      "32\n",
      "Accuracy: 0.64\n",
      "33\n",
      "Accuracy: 0.6\n",
      "34\n",
      "Accuracy: 0.6\n",
      "35\n",
      "Accuracy: 0.66\n",
      "36\n",
      "Accuracy: 0.62\n",
      "37\n",
      "Accuracy: 0.56\n",
      "38\n",
      "Accuracy: 0.62\n",
      "39\n",
      "Accuracy: 0.66\n",
      "40\n",
      "Accuracy: 0.68\n",
      "41\n",
      "Accuracy: 0.64\n",
      "42\n",
      "Accuracy: 0.64\n",
      "43\n",
      "Accuracy: 0.6\n",
      "44\n",
      "Accuracy: 0.56\n",
      "45\n",
      "Accuracy: 0.64\n",
      "46\n",
      "Accuracy: 0.7\n",
      "47\n",
      "Accuracy: 0.72\n",
      "48\n",
      "Accuracy: 0.66\n",
      "49\n",
      "Accuracy: 0.68\n",
      "50\n",
      "Accuracy: 0.7\n",
      "51\n",
      "Accuracy: 0.72\n",
      "52\n",
      "Accuracy: 0.58\n",
      "53\n",
      "Accuracy: 0.64\n",
      "54\n",
      "Accuracy: 0.66\n",
      "55\n",
      "Accuracy: 0.66\n",
      "56\n",
      "Accuracy: 0.72\n",
      "57\n",
      "Accuracy: 0.68\n",
      "58\n",
      "Accuracy: 0.6\n",
      "59\n",
      "Accuracy: 0.66\n",
      "60\n",
      "Accuracy: 0.56\n",
      "61\n",
      "Accuracy: 0.76\n",
      "62\n",
      "Accuracy: 0.68\n",
      "63\n",
      "Accuracy: 0.66\n",
      "64\n",
      "Accuracy: 0.66\n",
      "65\n",
      "Accuracy: 0.68\n",
      "66\n",
      "Accuracy: 0.62\n",
      "67\n",
      "Accuracy: 0.66\n",
      "68\n",
      "Accuracy: 0.64\n",
      "69\n",
      "Accuracy: 0.68\n",
      "70\n",
      "Accuracy: 0.68\n",
      "71\n",
      "Accuracy: 0.66\n",
      "72\n",
      "Accuracy: 0.82\n",
      "73\n",
      "Accuracy: 0.78\n",
      "74\n",
      "Accuracy: 0.64\n",
      "75\n",
      "Accuracy: 0.68\n",
      "76\n",
      "Accuracy: 0.74\n",
      "77\n",
      "Accuracy: 0.62\n",
      "78\n",
      "Accuracy: 0.62\n",
      "79\n",
      "Accuracy: 0.66\n",
      "80\n",
      "Accuracy: 0.64\n",
      "81\n",
      "Accuracy: 0.66\n",
      "82\n",
      "Accuracy: 0.74\n",
      "83\n",
      "Accuracy: 0.58\n",
      "84\n",
      "Accuracy: 0.7\n",
      "85\n",
      "Accuracy: 0.64\n",
      "86\n",
      "Accuracy: 0.72\n",
      "87\n",
      "Accuracy: 0.56\n",
      "88\n",
      "Accuracy: 0.68\n",
      "89\n",
      "Accuracy: 0.64\n",
      "90\n",
      "Accuracy: 0.66\n",
      "91\n",
      "Accuracy: 0.7\n",
      "92\n",
      "Accuracy: 0.76\n",
      "93\n",
      "Accuracy: 0.68\n",
      "94\n",
      "Accuracy: 0.74\n",
      "95\n",
      "Accuracy: 0.6\n",
      "96\n",
      "Accuracy: 0.84\n",
      "97\n",
      "Accuracy: 0.72\n",
      "98\n",
      "Accuracy: 0.64\n",
      "99\n",
      "Accuracy: 0.74\n",
      "100\n",
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    svm_model = SVC(kernel='rbf')\n",
    "    parameters = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "    svm_model = GridSearchCV(svm_model, parameters)\n",
    "    svm_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = svm_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100svmRadial.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff765ae6",
   "metadata": {},
   "source": [
    "### Individual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d2727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T14:11:41.018332Z",
     "start_time": "2023-02-14T14:11:08.582341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        svm_model = SVC(kernel='rbf')\n",
    "        parameters = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "        svm_model = GridSearchCV(svm_model, parameters)\n",
    "        svm_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = svm_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_svmR.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(svm_model, f\"{col}_svmR_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf1739",
   "metadata": {},
   "source": [
    "## SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ac8370a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T05:50:40.066412Z",
     "start_time": "2023-02-16T05:46:23.450116Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.66\n",
      "2\n",
      "Accuracy: 0.7\n",
      "3\n",
      "Accuracy: 0.78\n",
      "4\n",
      "Accuracy: 0.7\n",
      "5\n",
      "Accuracy: 0.74\n",
      "6\n",
      "Accuracy: 0.62\n",
      "7\n",
      "Accuracy: 0.7\n",
      "8\n",
      "Accuracy: 0.64\n",
      "9\n",
      "Accuracy: 0.78\n",
      "10\n",
      "Accuracy: 0.72\n",
      "11\n",
      "Accuracy: 0.72\n",
      "12\n",
      "Accuracy: 0.7\n",
      "13\n",
      "Accuracy: 0.66\n",
      "14\n",
      "Accuracy: 0.76\n",
      "15\n",
      "Accuracy: 0.68\n",
      "16\n",
      "Accuracy: 0.74\n",
      "17\n",
      "Accuracy: 0.74\n",
      "18\n",
      "Accuracy: 0.66\n",
      "19\n",
      "Accuracy: 0.8\n",
      "20\n",
      "Accuracy: 0.78\n",
      "21\n",
      "Accuracy: 0.76\n",
      "22\n",
      "Accuracy: 0.74\n",
      "23\n",
      "Accuracy: 0.74\n",
      "24\n",
      "Accuracy: 0.78\n",
      "25\n",
      "Accuracy: 0.74\n",
      "26\n",
      "Accuracy: 0.74\n",
      "27\n",
      "Accuracy: 0.72\n",
      "28\n",
      "Accuracy: 0.74\n",
      "29\n",
      "Accuracy: 0.72\n",
      "30\n",
      "Accuracy: 0.76\n",
      "31\n",
      "Accuracy: 0.76\n",
      "32\n",
      "Accuracy: 0.66\n",
      "33\n",
      "Accuracy: 0.72\n",
      "34\n",
      "Accuracy: 0.66\n",
      "35\n",
      "Accuracy: 0.78\n",
      "36\n",
      "Accuracy: 0.66\n",
      "37\n",
      "Accuracy: 0.7\n",
      "38\n",
      "Accuracy: 0.72\n",
      "39\n",
      "Accuracy: 0.72\n",
      "40\n",
      "Accuracy: 0.74\n",
      "41\n",
      "Accuracy: 0.72\n",
      "42\n",
      "Accuracy: 0.76\n",
      "43\n",
      "Accuracy: 0.6\n",
      "44\n",
      "Accuracy: 0.82\n",
      "45\n",
      "Accuracy: 0.74\n",
      "46\n",
      "Accuracy: 0.7\n",
      "47\n",
      "Accuracy: 0.72\n",
      "48\n",
      "Accuracy: 0.64\n",
      "49\n",
      "Accuracy: 0.72\n",
      "50\n",
      "Accuracy: 0.76\n",
      "51\n",
      "Accuracy: 0.76\n",
      "52\n",
      "Accuracy: 0.68\n",
      "53\n",
      "Accuracy: 0.74\n",
      "54\n",
      "Accuracy: 0.68\n",
      "55\n",
      "Accuracy: 0.7\n",
      "56\n",
      "Accuracy: 0.66\n",
      "57\n",
      "Accuracy: 0.64\n",
      "58\n",
      "Accuracy: 0.7\n",
      "59\n",
      "Accuracy: 0.72\n",
      "60\n",
      "Accuracy: 0.72\n",
      "61\n",
      "Accuracy: 0.78\n",
      "62\n",
      "Accuracy: 0.7\n",
      "63\n",
      "Accuracy: 0.74\n",
      "64\n",
      "Accuracy: 0.8\n",
      "65\n",
      "Accuracy: 0.62\n",
      "66\n",
      "Accuracy: 0.7\n",
      "67\n",
      "Accuracy: 0.72\n",
      "68\n",
      "Accuracy: 0.7\n",
      "69\n",
      "Accuracy: 0.76\n",
      "70\n",
      "Accuracy: 0.76\n",
      "71\n",
      "Accuracy: 0.8\n",
      "72\n",
      "Accuracy: 0.78\n",
      "73\n",
      "Accuracy: 0.7\n",
      "74\n",
      "Accuracy: 0.76\n",
      "75\n",
      "Accuracy: 0.74\n",
      "76\n",
      "Accuracy: 0.68\n",
      "77\n",
      "Accuracy: 0.62\n",
      "78\n",
      "Accuracy: 0.68\n",
      "79\n",
      "Accuracy: 0.66\n",
      "80\n",
      "Accuracy: 0.6\n",
      "81\n",
      "Accuracy: 0.76\n",
      "82\n",
      "Accuracy: 0.8\n",
      "83\n",
      "Accuracy: 0.7\n",
      "84\n",
      "Accuracy: 0.66\n",
      "85\n",
      "Accuracy: 0.78\n",
      "86\n",
      "Accuracy: 0.74\n",
      "87\n",
      "Accuracy: 0.72\n",
      "88\n",
      "Accuracy: 0.78\n",
      "89\n",
      "Accuracy: 0.74\n",
      "90\n",
      "Accuracy: 0.8\n",
      "91\n",
      "Accuracy: 0.72\n",
      "92\n",
      "Accuracy: 0.7\n",
      "93\n",
      "Accuracy: 0.76\n",
      "94\n",
      "Accuracy: 0.6\n",
      "95\n",
      "Accuracy: 0.74\n",
      "96\n",
      "Accuracy: 0.76\n",
      "97\n",
      "Accuracy: 0.72\n",
      "98\n",
      "Accuracy: 0.68\n",
      "99\n",
      "Accuracy: 0.78\n",
      "100\n",
      "Accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    svm_model = SVC(kernel='poly', degree=3)\n",
    "    parameters = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "    svm_model = GridSearchCV(svm_model, parameters)\n",
    "    svm_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = svm_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100svmPoly.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e8db0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-02-14T12:08:11.615Z"
    }
   },
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        svm_model = SVC(kernel='poly', degree=3)\n",
    "        parameters = {'C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100], 'gamma': [0.01, 0.1, 1, 10]}\n",
    "        svm_model = GridSearchCV(svm_model, parameters)\n",
    "        svm_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = svm_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_svmP.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(svm_model, f\"{col}_svmP_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab754f0",
   "metadata": {},
   "source": [
    "    hinge: This is the default loss function for the linear SVM classifier, which maximizes the margin between the two classes. It is also known as the max-margin hinge loss, and is typically used for binary classification problems.\n",
    "\n",
    "    log_loss: This is the logistic regression loss function, also known as the cross-entropy loss. It is used to train linear classifiers that predict class probabilities. It is suitable for both binary and multi-class classification problems.\n",
    "\n",
    "    modified_huber: This is a smoothed version of the hinge loss that is less sensitive to outliers. It combines the best properties of the hinge and log loss functions and is useful for noisy data and datasets with mislabeled samples.\n",
    "\n",
    "    squared_hinge: This is a variant of the hinge loss that is squared. It is more sensitive to samples that are closer to the decision boundary and can be used to train non-linear classifiers.\n",
    "\n",
    "    perceptron: This is the perceptron algorithm, which is a linear binary classifier. It updates the weight vector in each iteration using only the misclassified samples.\n",
    "\n",
    "    squared_error: This is the mean squared error (MSE) loss function, which is used to train linear regression models. It minimizes the sum of the squared errors between the predicted and actual target values.\n",
    "\n",
    "    huber: This is a robust regression loss function that combines the best properties of MSE and absolute error loss functions. It is less sensitive to outliers than the MSE loss and is useful for datasets with noisy or corrupted samples.\n",
    "\n",
    "    epsilon_insensitive: This is the epsilon-insensitive loss function, which is used for support vector regression (SVR). It ignores errors that are within a certain distance epsilon from the actual target value.\n",
    "\n",
    "    squared_epsilon_insensitive: This is a squared version of the epsilon-insensitive loss function, which is also used for SVR. It is more sensitive to larger errors than the regular epsilon-insensitive loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6e29b",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a19439",
   "metadata": {},
   "source": [
    "## Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20e927f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T16:46:09.150288Z",
     "start_time": "2023-02-15T13:41:04.627912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.04176122603564219\n",
      "Iteration 2\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.04882622246293482\n",
      "Iteration 3\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.044542114902640165\n",
      "Iteration 4\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.0626099033699941\n",
      "Iteration 5\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.047999999999999994\n",
      "Iteration 6\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.047497368348151665\n",
      "Iteration 7\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.060530983801686214\n",
      "Iteration 8\n",
      "Cross-validation accuracy: 0.804 +/- 0.07255342858886822\n",
      "Iteration 9\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.059866518188383046\n",
      "Iteration 10\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06248199740725322\n",
      "Iteration 11\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.059866518188383046\n",
      "Iteration 12\n",
      "Cross-validation accuracy: 0.844 +/- 0.07031358332498779\n",
      "Iteration 13\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.05122499389946279\n",
      "Iteration 14\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.0571314274283428\n",
      "Iteration 15\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.060530983801686235\n",
      "Iteration 16\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.06053098380168624\n",
      "Iteration 17\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.048166378315169185\n",
      "Iteration 18\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.04079215610874227\n",
      "Iteration 19\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.04472135954999579\n",
      "Iteration 20\n",
      "Cross-validation accuracy: 0.812 +/- 0.07386474125047754\n",
      "Iteration 21\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 22\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.054405882034941774\n",
      "Iteration 23\n",
      "Cross-validation accuracy: 0.808 +/- 0.034871191548325374\n",
      "Iteration 24\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.04079215610874226\n",
      "Iteration 25\n",
      "Cross-validation accuracy: 0.808 +/- 0.07110555533852471\n",
      "Iteration 26\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.047999999999999994\n",
      "Iteration 27\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.04098780306383839\n",
      "Iteration 28\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.05122499389946279\n",
      "Iteration 29\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.06939740629158991\n",
      "Iteration 30\n",
      "Cross-validation accuracy: 0.796 +/- 0.04176122603564219\n",
      "Iteration 31\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06400000000000002\n",
      "Iteration 32\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.07838367176906169\n",
      "Iteration 33\n",
      "Cross-validation accuracy: 0.8 +/- 0.05059644256269407\n",
      "Iteration 34\n",
      "Cross-validation accuracy: 0.8 +/- 0.06693280212272604\n",
      "Iteration 35\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.05381449618829484\n",
      "Iteration 36\n",
      "Cross-validation accuracy: 0.804 +/- 0.063118935352238\n",
      "Iteration 37\n",
      "Cross-validation accuracy: 0.812 +/- 0.02561249694973137\n",
      "Iteration 38\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.046647615158762396\n",
      "Iteration 39\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.04079215610874227\n",
      "Iteration 40\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 41\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06499230723708767\n",
      "Iteration 42\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.054258639865002144\n",
      "Iteration 43\n",
      "Cross-validation accuracy: 0.808 +/- 0.04995998398718718\n",
      "Iteration 44\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.04454211490264017\n",
      "Iteration 45\n",
      "Cross-validation accuracy: 0.812 +/- 0.05670978751503129\n",
      "Iteration 46\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.061449165982948875\n",
      "Iteration 47\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.04098780306383838\n",
      "Iteration 48\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.057131427428342776\n",
      "Iteration 49\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.04176122603564219\n",
      "Iteration 50\n",
      "Cross-validation accuracy: 0.808 +/- 0.06399999999999999\n",
      "Iteration 51\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.04543126676640218\n",
      "Iteration 52\n",
      "Cross-validation accuracy: 0.784 +/- 0.06974238309665076\n",
      "Iteration 53\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.04472135954999579\n",
      "Iteration 54\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.06462197768561405\n",
      "Iteration 55\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.044542114902640165\n",
      "Iteration 56\n",
      "Cross-validation accuracy: 0.812 +/- 0.04749736834815167\n",
      "Iteration 57\n",
      "Cross-validation accuracy: 0.812 +/- 0.050754310161798086\n",
      "Iteration 58\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.08236504112789601\n",
      "Iteration 59\n",
      "Cross-validation accuracy: 0.808 +/- 0.053065996645686404\n",
      "Iteration 60\n",
      "Cross-validation accuracy: 0.812 +/- 0.0620966987850401\n",
      "Iteration 61\n",
      "Cross-validation accuracy: 0.792 +/- 0.055999999999999994\n",
      "Iteration 62\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.044\n",
      "Iteration 63\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.03599999999999998\n",
      "Iteration 64\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06752777206453651\n",
      "Iteration 65\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.04749736834815166\n",
      "Iteration 66\n",
      "Cross-validation accuracy: 0.812 +/- 0.047497368348151665\n",
      "Iteration 67\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.054258639865002144\n",
      "Iteration 68\n",
      "Cross-validation accuracy: 0.8400000000000001 +/- 0.035777087639996624\n",
      "Iteration 69\n",
      "Cross-validation accuracy: 0.8 +/- 0.05059644256269404\n",
      "Iteration 70\n",
      "Cross-validation accuracy: 0.792 +/- 0.05600000000000001\n",
      "Iteration 71\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.04995998398718718\n",
      "Iteration 72\n",
      "Cross-validation accuracy: 0.804 +/- 0.06053098380168621\n",
      "Iteration 73\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06260990336999413\n",
      "Iteration 74\n",
      "Cross-validation accuracy: 0.812 +/- 0.044\n",
      "Iteration 75\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.047999999999999994\n",
      "Iteration 76\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.046647615158762396\n",
      "Iteration 77\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.054405882034941774\n",
      "Iteration 78\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.054258639865002144\n",
      "Iteration 79\n",
      "Cross-validation accuracy: 0.808 +/- 0.064\n",
      "Iteration 80\n",
      "Cross-validation accuracy: 0.808 +/- 0.04995998398718718\n",
      "Iteration 81\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.04995998398718718\n",
      "Iteration 82\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.04472135954999579\n",
      "Iteration 83\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.047999999999999994\n",
      "Iteration 84\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.059866518188383074\n",
      "Iteration 85\n",
      "Cross-validation accuracy: 0.82 +/- 0.036878177829171535\n",
      "Iteration 86\n",
      "Cross-validation accuracy: 0.8 +/- 0.0593295878967653\n",
      "Iteration 87\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.047999999999999994\n",
      "Iteration 88\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.04882622246293481\n",
      "Iteration 89\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.0366606055596467\n",
      "Iteration 90\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.047999999999999994\n",
      "Iteration 91\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.05138093031466051\n",
      "Iteration 92\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.0571314274283428\n",
      "Iteration 93\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.04995998398718719\n",
      "Iteration 94\n",
      "Cross-validation accuracy: 0.8 +/- 0.08197560612767678\n",
      "Iteration 95\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.04308131845707602\n",
      "Iteration 96\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.05782732917920385\n",
      "Iteration 97\n",
      "Cross-validation accuracy: 0.8360000000000001 +/- 0.03322649545167228\n",
      "Iteration 98\n",
      "Cross-validation accuracy: 0.804 +/- 0.04176122603564219\n",
      "Iteration 99\n",
      "Cross-validation accuracy: 0.812 +/- 0.04749736834815167\n",
      "Iteration 100\n",
      "Cross-validation accuracy: 0.792 +/- 0.061449165982948833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(f'Iteration {i}')\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    rf_model = RandomForestClassifier()\n",
    "    ada_model = AdaBoostClassifier(base_estimator=rf_model)\n",
    "    parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "    ada_model = GridSearchCV(ada_model, parameters)\n",
    "    cv_scores = cross_val_score(ada_model, X, y, cv=10)\n",
    "    mean_accuracy = np.mean(cv_scores)\n",
    "    std_accuracy = np.std(cv_scores)\n",
    "    print(f'Cross-validation accuracy: {mean_accuracy} +/- {std_accuracy}')\n",
    "    output.append(mean_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100AdaBoost.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba31f140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:11:48.400289Z",
     "start_time": "2023-02-15T04:53:53.017349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.84\n",
      "2\n",
      "Accuracy: 0.88\n",
      "3\n",
      "Accuracy: 0.92\n",
      "4\n",
      "Accuracy: 0.78\n",
      "5\n",
      "Accuracy: 0.9\n",
      "6\n",
      "Accuracy: 0.86\n",
      "7\n",
      "Accuracy: 0.82\n",
      "8\n",
      "Accuracy: 0.84\n",
      "9\n",
      "Accuracy: 0.82\n",
      "10\n",
      "Accuracy: 0.78\n",
      "11\n",
      "Accuracy: 0.82\n",
      "12\n",
      "Accuracy: 0.82\n",
      "13\n",
      "Accuracy: 0.76\n",
      "14\n",
      "Accuracy: 0.88\n",
      "15\n",
      "Accuracy: 0.84\n",
      "16\n",
      "Accuracy: 0.76\n",
      "17\n",
      "Accuracy: 0.78\n",
      "18\n",
      "Accuracy: 0.84\n",
      "19\n",
      "Accuracy: 0.92\n",
      "20\n",
      "Accuracy: 0.78\n",
      "21\n",
      "Accuracy: 0.92\n",
      "22\n",
      "Accuracy: 0.8\n",
      "23\n",
      "Accuracy: 0.82\n",
      "24\n",
      "Accuracy: 0.84\n",
      "25\n",
      "Accuracy: 0.8\n",
      "26\n",
      "Accuracy: 0.78\n",
      "27\n",
      "Accuracy: 0.8\n",
      "28\n",
      "Accuracy: 0.86\n",
      "29\n",
      "Accuracy: 0.86\n",
      "30\n",
      "Accuracy: 0.84\n",
      "31\n",
      "Accuracy: 0.72\n",
      "32\n",
      "Accuracy: 0.8\n",
      "33\n",
      "Accuracy: 0.88\n",
      "34\n",
      "Accuracy: 0.86\n",
      "35\n",
      "Accuracy: 0.8\n",
      "36\n",
      "Accuracy: 0.86\n",
      "37\n",
      "Accuracy: 0.84\n",
      "38\n",
      "Accuracy: 0.78\n",
      "39\n",
      "Accuracy: 0.8\n",
      "40\n",
      "Accuracy: 0.84\n",
      "41\n",
      "Accuracy: 0.84\n",
      "42\n",
      "Accuracy: 0.74\n",
      "43\n",
      "Accuracy: 0.78\n",
      "44\n",
      "Accuracy: 0.8\n",
      "45\n",
      "Accuracy: 0.84\n",
      "46\n",
      "Accuracy: 0.86\n",
      "47\n",
      "Accuracy: 0.9\n",
      "48\n",
      "Accuracy: 0.82\n",
      "49\n",
      "Accuracy: 0.8\n",
      "50\n",
      "Accuracy: 0.94\n",
      "51\n",
      "Accuracy: 0.88\n",
      "52\n",
      "Accuracy: 0.8\n",
      "53\n",
      "Accuracy: 0.84\n",
      "54\n",
      "Accuracy: 0.76\n",
      "55\n",
      "Accuracy: 0.84\n",
      "56\n",
      "Accuracy: 0.84\n",
      "57\n",
      "Accuracy: 0.84\n",
      "58\n",
      "Accuracy: 0.86\n",
      "59\n",
      "Accuracy: 0.82\n",
      "60\n",
      "Accuracy: 0.82\n",
      "61\n",
      "Accuracy: 0.82\n",
      "62\n",
      "Accuracy: 0.82\n",
      "63\n",
      "Accuracy: 0.8\n",
      "64\n",
      "Accuracy: 0.76\n",
      "65\n",
      "Accuracy: 0.86\n",
      "66\n",
      "Accuracy: 0.74\n",
      "67\n",
      "Accuracy: 0.78\n",
      "68\n",
      "Accuracy: 0.88\n",
      "69\n",
      "Accuracy: 0.88\n",
      "70\n",
      "Accuracy: 0.86\n",
      "71\n",
      "Accuracy: 0.82\n",
      "72\n",
      "Accuracy: 0.82\n",
      "73\n",
      "Accuracy: 0.78\n",
      "74\n",
      "Accuracy: 0.9\n",
      "75\n",
      "Accuracy: 0.76\n",
      "76\n",
      "Accuracy: 0.88\n",
      "77\n",
      "Accuracy: 0.8\n",
      "78\n",
      "Accuracy: 0.8\n",
      "79\n",
      "Accuracy: 0.8\n",
      "80\n",
      "Accuracy: 0.84\n",
      "81\n",
      "Accuracy: 0.86\n",
      "82\n",
      "Accuracy: 0.8\n",
      "83\n",
      "Accuracy: 0.9\n",
      "84\n",
      "Accuracy: 0.88\n",
      "85\n",
      "Accuracy: 0.86\n",
      "86\n",
      "Accuracy: 0.82\n",
      "87\n",
      "Accuracy: 0.78\n",
      "88\n",
      "Accuracy: 0.78\n",
      "89\n",
      "Accuracy: 0.88\n",
      "90\n",
      "Accuracy: 0.82\n",
      "91\n",
      "Accuracy: 0.82\n",
      "92\n",
      "Accuracy: 0.82\n",
      "93\n",
      "Accuracy: 0.8\n",
      "94\n",
      "Accuracy: 0.88\n",
      "95\n",
      "Accuracy: 0.74\n",
      "96\n",
      "Accuracy: 0.82\n",
      "97\n",
      "Accuracy: 0.8\n",
      "98\n",
      "Accuracy: 0.82\n",
      "99\n",
      "Accuracy: 0.84\n",
      "100\n",
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    rf_model = RandomForestClassifier()\n",
    "    ada_model = AdaBoostClassifier(base_estimator=rf_model)\n",
    "    parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "    ada_model = GridSearchCV(ada_model, parameters)\n",
    "    ada_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = ada_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100AdaBoost.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00bb5fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T10:23:51.802829Z",
     "start_time": "2023-02-25T08:53:15.495955Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for column Anxiety: 0.7\n",
      "Accuracy for column Apathy: 0.7\n",
      "Accuracy for column Benton: 0.72\n",
      "Accuracy for column Clock: 0.58\n",
      "Accuracy for column Cognition: 0.56\n",
      "Accuracy for column COGSTATE: 0.72\n",
      "Accuracy for column Constipate: 0.68\n",
      "Accuracy for column Depress: 0.6\n",
      "Accuracy for column DopaDefic: 0.58\n",
      "Accuracy for column Education: 0.66\n",
      "Accuracy for column Epworth: 0.66\n",
      "Accuracy for column Fatigue: 0.76\n",
      "Accuracy for column Geriatric_Depression: 0.66\n",
      "Accuracy for column Hallucination: 0.64\n",
      "Accuracy for column Hand: 0.7\n",
      "Accuracy for column Hopkins: 0.62\n",
      "Accuracy for column Hopkins_Recog: 0.6\n",
      "Accuracy for column Impulsive_CompulsiveBehavior: 0.64\n",
      "Accuracy for column Impulsive_ICD: 0.64\n",
      "Accuracy for column LetterNumber: 0.64\n",
      "Accuracy for column Lexical_Fluency: 0.6\n",
      "Accuracy for column LightHead: 0.68\n",
      "Accuracy for column Modif_Boston: 0.52\n",
      "Accuracy for column Montreal_Cognitive: 0.68\n",
      "Accuracy for column Pain: 0.72\n",
      "Accuracy for column REM_AwakeDream: 0.6\n",
      "Accuracy for column REM_AwakeProblem: 0.66\n",
      "Accuracy for column REM_Dream: 0.7\n",
      "Accuracy for column REM_Movement: 0.64\n",
      "Accuracy for column SCOPA_Cardio: 0.72\n",
      "Accuracy for column SCOPA_Eye: 0.66\n",
      "Accuracy for column SCOPA_Gastro: 0.62\n",
      "Accuracy for column SCOPA_Sex: 0.7\n",
      "Accuracy for column SCOPA_Thermo: 0.8\n",
      "Accuracy for column SCOPA_Urine: 0.48\n",
      "Accuracy for column Semantic: 0.56\n",
      "Accuracy for column SleepDay: 0.66\n",
      "Accuracy for column SleepNight: 0.62\n",
      "Accuracy for column STAIA: 0.6\n",
      "Accuracy for column STAIS: 0.66\n",
      "Accuracy for column Symbol_Digit: 0.68\n",
      "Accuracy for column Trail_Making_A: 0.62\n",
      "Accuracy for column Trail_Making_B: 0.62\n",
      "Accuracy for column UPSIT: 0.78\n",
      "Accuracy for column Urine: 0.62\n"
     ]
    }
   ],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                            NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        rf_model = RandomForestClassifier()\n",
    "        ada_model = AdaBoostClassifier(base_estimator=rf_model)\n",
    "        parameters = {'n_estimators': [300], 'learning_rate': [0.1]}\n",
    "        ada_model = GridSearchCV(ada_model, parameters, n_jobs=-1)\n",
    "        ada_model.fit(train_data, train_labels)\n",
    "\n",
    "        predictions = ada_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_AdaBoost.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(ada_model, f\"{col}_AdaBoost_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2473da4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:53:13.385896Z",
     "start_time": "2023-02-25T08:49:06.438064Z"
    }
   },
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_column(col):\n",
    "    output = []\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], NonMot1['APPRDX'], test_size=0.2)\n",
    "    rf_model = RandomForestClassifier()\n",
    "    ada_model = AdaBoostClassifier(base_estimator=rf_model)\n",
    "    parameters = {'n_estimators': [300], 'learning_rate': [0.1]}\n",
    "    ada_model = GridSearchCV(ada_model, parameters, n_jobs=-1)\n",
    "    ada_model.fit(train_data, train_labels)\n",
    "    predictions = ada_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy for column {col}: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "    np.savetxt(f\"{col}_AdaBoost.csv\", output, delimiter=\",\")\n",
    "    joblib.dump(ada_model, f\"{col}_AdaBoost_model.joblib\")\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(process_column)(col) for col in NonMot1.columns if col != 'APPRDX')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1a9c1",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c92a281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T18:27:26.871746Z",
     "start_time": "2023-02-16T05:52:40.447743Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 2\n",
      "Cross-validation accuracy: 0.808 +/- 0.07547184905645282\n",
      "Iteration 3\n",
      "Cross-validation accuracy: 0.808 +/- 0.07110555533852471\n",
      "Iteration 4\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 5\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 6\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 7\n",
      "Cross-validation accuracy: 0.82 +/- 0.0626099033699941\n",
      "Iteration 8\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 9\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 10\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.08616263691415205\n",
      "Iteration 11\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.06740919818541084\n",
      "Iteration 12\n",
      "Cross-validation accuracy: 0.82 +/- 0.0698569967862919\n",
      "Iteration 13\n",
      "Cross-validation accuracy: 0.836 +/- 0.07031358332498774\n",
      "Iteration 14\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 15\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 16\n",
      "Cross-validation accuracy: 0.828 +/- 0.07386474125047753\n",
      "Iteration 17\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 18\n",
      "Cross-validation accuracy: 0.828 +/- 0.06939740629158986\n",
      "Iteration 19\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 20\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07631513611335564\n",
      "Iteration 21\n",
      "Cross-validation accuracy: 0.82 +/- 0.07429670248402682\n",
      "Iteration 22\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.0626099033699941\n",
      "Iteration 23\n",
      "Cross-validation accuracy: 0.82 +/- 0.08049844718999241\n",
      "Iteration 24\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 25\n",
      "Cross-validation accuracy: 0.82 +/- 0.07429670248402682\n",
      "Iteration 26\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 27\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 28\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 29\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.06462197768561403\n",
      "Iteration 30\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07631513611335564\n",
      "Iteration 31\n",
      "Cross-validation accuracy: 0.828 +/- 0.07386474125047753\n",
      "Iteration 32\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 33\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07199999999999997\n",
      "Iteration 34\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.07418894796396562\n",
      "Iteration 35\n",
      "Cross-validation accuracy: 0.804 +/- 0.07255342858886822\n",
      "Iteration 36\n",
      "Cross-validation accuracy: 0.812 +/- 0.06705221845696083\n",
      "Iteration 37\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 38\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 39\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 40\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.07211102550927977\n",
      "Iteration 41\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.07332121111929342\n",
      "Iteration 42\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07631513611335564\n",
      "Iteration 43\n",
      "Cross-validation accuracy: 0.828 +/- 0.07166589146867565\n",
      "Iteration 44\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07199999999999997\n",
      "Iteration 45\n",
      "Cross-validation accuracy: 0.82 +/- 0.07429670248402682\n",
      "Iteration 46\n",
      "Cross-validation accuracy: 0.82 +/- 0.08049844718999241\n",
      "Iteration 47\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.0741889479639656\n",
      "Iteration 48\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 49\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07199999999999997\n",
      "Iteration 50\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06248199740725322\n",
      "Iteration 51\n",
      "Cross-validation accuracy: 0.82 +/- 0.07641989269817119\n",
      "Iteration 52\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 53\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.06740919818541086\n",
      "Iteration 54\n",
      "Cross-validation accuracy: 0.804 +/- 0.07683749084919418\n",
      "Iteration 55\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 56\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 57\n",
      "Cross-validation accuracy: 0.828 +/- 0.07386474125047753\n",
      "Iteration 58\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.08236504112789601\n",
      "Iteration 59\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.06740919818541086\n",
      "Iteration 60\n",
      "Cross-validation accuracy: 0.82 +/- 0.07429670248402682\n",
      "Iteration 61\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07199999999999997\n",
      "Iteration 62\n",
      "Cross-validation accuracy: 0.828 +/- 0.07386474125047754\n",
      "Iteration 63\n",
      "Cross-validation accuracy: 0.8280000000000001 +/- 0.07166589146867566\n",
      "Iteration 64\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 65\n",
      "Cross-validation accuracy: 0.804 +/- 0.0747261667690776\n",
      "Iteration 66\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.07110555533852468\n",
      "Iteration 67\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06985699678629191\n",
      "Iteration 68\n",
      "Cross-validation accuracy: 0.812 +/- 0.059464274989274014\n",
      "Iteration 69\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06499230723708767\n",
      "Iteration 70\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.0741889479639656\n",
      "Iteration 71\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 72\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.07211102550927977\n",
      "Iteration 73\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.08616263691415205\n",
      "Iteration 74\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 75\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06399999999999999\n",
      "Iteration 76\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.06740919818541086\n",
      "Iteration 77\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.06740919818541086\n",
      "Iteration 78\n",
      "Cross-validation accuracy: 0.82 +/- 0.0626099033699941\n",
      "Iteration 79\n",
      "Cross-validation accuracy: 0.836 +/- 0.07031358332498774\n",
      "Iteration 80\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 81\n",
      "Cross-validation accuracy: 0.8200000000000001 +/- 0.06511528238439881\n",
      "Iteration 82\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.07838367176906168\n",
      "Iteration 83\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.07199999999999998\n",
      "Iteration 84\n",
      "Cross-validation accuracy: 0.828 +/- 0.07386474125047753\n",
      "Iteration 85\n",
      "Cross-validation accuracy: 0.808 +/- 0.06399999999999999\n",
      "Iteration 86\n",
      "Cross-validation accuracy: 0.804 +/- 0.06799999999999999\n",
      "Iteration 87\n",
      "Cross-validation accuracy: 0.82 +/- 0.07429670248402682\n",
      "Iteration 88\n",
      "Cross-validation accuracy: 0.828 +/- 0.050754310161798086\n",
      "Iteration 89\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07631513611335564\n",
      "Iteration 90\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07631513611335564\n",
      "Iteration 91\n",
      "Cross-validation accuracy: 0.8160000000000001 +/- 0.07418894796396562\n",
      "Iteration 92\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.06740919818541086\n",
      "Iteration 93\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07418894796396562\n",
      "Iteration 94\n",
      "Cross-validation accuracy: 0.812 +/- 0.07166589146867566\n",
      "Iteration 95\n",
      "Cross-validation accuracy: 0.828 +/- 0.06939740629158986\n",
      "Iteration 96\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.07631513611335564\n",
      "Iteration 97\n",
      "Cross-validation accuracy: 0.808 +/- 0.07110555533852471\n",
      "Iteration 98\n",
      "Cross-validation accuracy: 0.82 +/- 0.0626099033699941\n",
      "Iteration 99\n",
      "Cross-validation accuracy: 0.8240000000000001 +/- 0.062481997407253215\n",
      "Iteration 100\n",
      "Cross-validation accuracy: 0.82 +/- 0.0626099033699941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(f'Iteration {i}')\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    gb_model = GradientBoostingClassifier()\n",
    "    parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10], 'max_depth': [3, 4, 5]}\n",
    "    gb_model = GridSearchCV(gb_model, parameters)\n",
    "    cv_scores = cross_val_score(gb_model, X, y, cv=10)\n",
    "    mean_accuracy = np.mean(cv_scores)\n",
    "    std_accuracy = np.std(cv_scores)\n",
    "    print(f'Cross-validation accuracy: {mean_accuracy} +/- {std_accuracy}')\n",
    "    output.append(mean_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100GradientBoost.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca1b2cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:46:03.541128Z",
     "start_time": "2023-02-15T05:26:49.770886Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.92\n",
      "2\n",
      "Accuracy: 0.8\n",
      "3\n",
      "Accuracy: 0.86\n",
      "4\n",
      "Accuracy: 0.92\n",
      "5\n",
      "Accuracy: 0.8\n",
      "6\n",
      "Accuracy: 0.84\n",
      "7\n",
      "Accuracy: 0.84\n",
      "8\n",
      "Accuracy: 0.76\n",
      "9\n",
      "Accuracy: 0.92\n",
      "10\n",
      "Accuracy: 0.82\n",
      "11\n",
      "Accuracy: 0.92\n",
      "12\n",
      "Accuracy: 0.8\n",
      "13\n",
      "Accuracy: 0.76\n",
      "14\n",
      "Accuracy: 0.8\n",
      "15\n",
      "Accuracy: 0.76\n",
      "16\n",
      "Accuracy: 0.8\n",
      "17\n",
      "Accuracy: 0.9\n",
      "18\n",
      "Accuracy: 0.84\n",
      "19\n",
      "Accuracy: 0.88\n",
      "20\n",
      "Accuracy: 0.82\n",
      "21\n",
      "Accuracy: 0.86\n",
      "22\n",
      "Accuracy: 0.76\n",
      "23\n",
      "Accuracy: 0.86\n",
      "24\n",
      "Accuracy: 0.86\n",
      "25\n",
      "Accuracy: 0.86\n",
      "26\n",
      "Accuracy: 0.82\n",
      "27\n",
      "Accuracy: 0.8\n",
      "28\n",
      "Accuracy: 0.88\n",
      "29\n",
      "Accuracy: 0.74\n",
      "30\n",
      "Accuracy: 0.86\n",
      "31\n",
      "Accuracy: 0.8\n",
      "32\n",
      "Accuracy: 0.84\n",
      "33\n",
      "Accuracy: 0.86\n",
      "34\n",
      "Accuracy: 0.9\n",
      "35\n",
      "Accuracy: 0.84\n",
      "36\n",
      "Accuracy: 0.86\n",
      "37\n",
      "Accuracy: 0.88\n",
      "38\n",
      "Accuracy: 0.86\n",
      "39\n",
      "Accuracy: 0.74\n",
      "40\n",
      "Accuracy: 0.82\n",
      "41\n",
      "Accuracy: 0.86\n",
      "42\n",
      "Accuracy: 0.84\n",
      "43\n",
      "Accuracy: 0.88\n",
      "44\n",
      "Accuracy: 0.84\n",
      "45\n",
      "Accuracy: 0.82\n",
      "46\n",
      "Accuracy: 0.88\n",
      "47\n",
      "Accuracy: 0.82\n",
      "48\n",
      "Accuracy: 0.84\n",
      "49\n",
      "Accuracy: 0.86\n",
      "50\n",
      "Accuracy: 0.86\n",
      "51\n",
      "Accuracy: 0.88\n",
      "52\n",
      "Accuracy: 0.82\n",
      "53\n",
      "Accuracy: 0.82\n",
      "54\n",
      "Accuracy: 0.86\n",
      "55\n",
      "Accuracy: 0.82\n",
      "56\n",
      "Accuracy: 0.88\n",
      "57\n",
      "Accuracy: 0.84\n",
      "58\n",
      "Accuracy: 0.86\n",
      "59\n",
      "Accuracy: 0.92\n",
      "60\n",
      "Accuracy: 0.78\n",
      "61\n",
      "Accuracy: 0.8\n",
      "62\n",
      "Accuracy: 0.88\n",
      "63\n",
      "Accuracy: 0.86\n",
      "64\n",
      "Accuracy: 0.78\n",
      "65\n",
      "Accuracy: 0.8\n",
      "66\n",
      "Accuracy: 0.8\n",
      "67\n",
      "Accuracy: 0.84\n",
      "68\n",
      "Accuracy: 0.84\n",
      "69\n",
      "Accuracy: 0.8\n",
      "70\n",
      "Accuracy: 0.82\n",
      "71\n",
      "Accuracy: 0.84\n",
      "72\n",
      "Accuracy: 0.82\n",
      "73\n",
      "Accuracy: 0.84\n",
      "74\n",
      "Accuracy: 0.8\n",
      "75\n",
      "Accuracy: 0.92\n",
      "76\n",
      "Accuracy: 0.72\n",
      "77\n",
      "Accuracy: 0.7\n",
      "78\n",
      "Accuracy: 0.8\n",
      "79\n",
      "Accuracy: 0.76\n",
      "80\n",
      "Accuracy: 0.7\n",
      "81\n",
      "Accuracy: 0.8\n",
      "82\n",
      "Accuracy: 0.86\n",
      "83\n",
      "Accuracy: 0.84\n",
      "84\n",
      "Accuracy: 0.84\n",
      "85\n",
      "Accuracy: 0.9\n",
      "86\n",
      "Accuracy: 0.9\n",
      "87\n",
      "Accuracy: 0.74\n",
      "88\n",
      "Accuracy: 0.86\n",
      "89\n",
      "Accuracy: 0.84\n",
      "90\n",
      "Accuracy: 0.78\n",
      "91\n",
      "Accuracy: 0.82\n",
      "92\n",
      "Accuracy: 0.88\n",
      "93\n",
      "Accuracy: 0.9\n",
      "94\n",
      "Accuracy: 0.76\n",
      "95\n",
      "Accuracy: 0.82\n",
      "96\n",
      "Accuracy: 0.68\n",
      "97\n",
      "Accuracy: 0.82\n",
      "98\n",
      "Accuracy: 0.8\n",
      "99\n",
      "Accuracy: 0.78\n",
      "100\n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    gb_model = GradientBoostingClassifier()   \n",
    "    parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "    gb_model = GridSearchCV(gb_model, parameters)\n",
    "    gb_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = gb_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100GradientBoosting.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e94336",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:26:45.054678Z",
     "start_time": "2023-02-15T05:26:45.054678Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                NonMot1['APPRDX'], test_size=0.2)\n",
    "\n",
    "        rf_model = RandomForestClassifier()\n",
    "        gb_model = GradientBoostingClassifier(base_estimator=rf_model)\n",
    "        gb_model = GradientBoostingClassifier()\n",
    "        parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "        gb_model = GridSearchCV(gb_model, parameters)\n",
    "        gb_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = gb_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_GradBoost.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(gb_model, f\"{col}_GradBoost_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e96490",
   "metadata": {},
   "source": [
    "## Extra Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1bcd5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T04:22:23.993268Z",
     "start_time": "2023-02-17T04:22:23.946410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPRDX</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Apathy</th>\n",
       "      <th>Benton</th>\n",
       "      <th>Clock</th>\n",
       "      <th>Cognition</th>\n",
       "      <th>COGSTATE</th>\n",
       "      <th>Constipate</th>\n",
       "      <th>Depress</th>\n",
       "      <th>DopaDefic</th>\n",
       "      <th>...</th>\n",
       "      <th>Semantic</th>\n",
       "      <th>SleepDay</th>\n",
       "      <th>SleepNight</th>\n",
       "      <th>STAIA</th>\n",
       "      <th>STAIS</th>\n",
       "      <th>Symbol_Digit</th>\n",
       "      <th>Trail_Making_A</th>\n",
       "      <th>Trail_Making_B</th>\n",
       "      <th>UPSIT</th>\n",
       "      <th>Urine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>59</td>\n",
       "      <td>47.5</td>\n",
       "      <td>110</td>\n",
       "      <td>204</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.76</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPRDX  Anxiety  Apathy  Benton  Clock  Cognition  COGSTATE  Constipate  \\\n",
       "0       0        1       0   12.16      7          1         1           1   \n",
       "1       0        1       1    7.76      6          1         1           0   \n",
       "\n",
       "   Depress  DopaDefic  ...  Semantic  SleepDay  SleepNight  STAIA  STAIS  \\\n",
       "0        1          0  ...        57         1           0     45     59   \n",
       "1        0          0  ...        36         1           3     40     39   \n",
       "\n",
       "   Symbol_Digit  Trail_Making_A  Trail_Making_B  UPSIT  Urine  \n",
       "0          47.5             110             204     17      1  \n",
       "1          52.0              27              52      9      0  \n",
       "\n",
       "[2 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NonMot1['APPRDX'] = NonMot1['APPRDX'].replace(['Patient'], 0)\n",
    "NonMot1['APPRDX'] = NonMot1['APPRDX'].replace(['Healthy'], 1)\n",
    "NonMot1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f577fb43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T06:11:44.131709Z",
     "start_time": "2023-02-17T04:22:28.530627Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 2\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 3\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 4\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 5\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 6\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 7\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 8\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 9\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 10\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 11\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 12\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 13\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 14\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 15\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 16\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 17\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 18\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 19\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 20\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 21\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 22\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 23\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 24\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 25\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 26\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 27\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 28\n",
      "Cross-validation accuracy: 0.8320000000000001 +/- 0.06645299090334458\n",
      "Iteration 29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]}\n\u001b[0;32m     10\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m GridSearchCV(xgb_model, parameters)\n\u001b[1;32m---> 11\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m mean_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cv_scores)\n\u001b[0;32m     13\u001b[0m std_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(cv_scores)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:509\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    507\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 509\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(f'Iteration {i}')\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10], 'max_depth': [3, 4, 5]}\n",
    "    xgb_model = GridSearchCV(xgb_model, parameters)\n",
    "    cv_scores = cross_val_score(xgb_model, X, y, cv=10)\n",
    "    mean_accuracy = np.mean(cv_scores)\n",
    "    std_accuracy = np.std(cv_scores)\n",
    "    print(f'Cross-validation accuracy: {mean_accuracy} +/- {std_accuracy}')\n",
    "    output.append(mean_accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100XGBClassifier.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39cd53e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T06:26:57.287867Z",
     "start_time": "2023-02-17T06:14:09.481642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.88\n",
      "2\n",
      "Accuracy: 0.8\n",
      "3\n",
      "Accuracy: 0.84\n",
      "4\n",
      "Accuracy: 0.86\n",
      "5\n",
      "Accuracy: 0.88\n",
      "6\n",
      "Accuracy: 0.88\n",
      "7\n",
      "Accuracy: 0.82\n",
      "8\n",
      "Accuracy: 0.78\n",
      "9\n",
      "Accuracy: 0.86\n",
      "10\n",
      "Accuracy: 0.82\n",
      "11\n",
      "Accuracy: 0.82\n",
      "12\n",
      "Accuracy: 0.8\n",
      "13\n",
      "Accuracy: 0.92\n",
      "14\n",
      "Accuracy: 0.78\n",
      "15\n",
      "Accuracy: 0.82\n",
      "16\n",
      "Accuracy: 0.9\n",
      "17\n",
      "Accuracy: 0.8\n",
      "18\n",
      "Accuracy: 0.9\n",
      "19\n",
      "Accuracy: 0.9\n",
      "20\n",
      "Accuracy: 0.86\n",
      "21\n",
      "Accuracy: 0.82\n",
      "22\n",
      "Accuracy: 0.82\n",
      "23\n",
      "Accuracy: 0.82\n",
      "24\n",
      "Accuracy: 0.92\n",
      "25\n",
      "Accuracy: 0.92\n",
      "26\n",
      "Accuracy: 0.8\n",
      "27\n",
      "Accuracy: 0.84\n",
      "28\n",
      "Accuracy: 0.86\n",
      "29\n",
      "Accuracy: 0.86\n",
      "30\n",
      "Accuracy: 0.78\n",
      "31\n",
      "Accuracy: 0.86\n",
      "32\n",
      "Accuracy: 0.86\n",
      "33\n",
      "Accuracy: 0.82\n",
      "34\n",
      "Accuracy: 0.8\n",
      "35\n",
      "Accuracy: 0.86\n",
      "36\n",
      "Accuracy: 0.8\n",
      "37\n",
      "Accuracy: 0.78\n",
      "38\n",
      "Accuracy: 0.82\n",
      "39\n",
      "Accuracy: 0.84\n",
      "40\n",
      "Accuracy: 0.8\n",
      "41\n",
      "Accuracy: 0.78\n",
      "42\n",
      "Accuracy: 0.78\n",
      "43\n",
      "Accuracy: 0.9\n",
      "44\n",
      "Accuracy: 0.74\n",
      "45\n",
      "Accuracy: 0.74\n",
      "46\n",
      "Accuracy: 0.86\n",
      "47\n",
      "Accuracy: 0.82\n",
      "48\n",
      "Accuracy: 0.78\n",
      "49\n",
      "Accuracy: 0.9\n",
      "50\n",
      "Accuracy: 0.78\n",
      "51\n",
      "Accuracy: 0.74\n",
      "52\n",
      "Accuracy: 0.82\n",
      "53\n",
      "Accuracy: 0.72\n",
      "54\n",
      "Accuracy: 0.86\n",
      "55\n",
      "Accuracy: 0.76\n",
      "56\n",
      "Accuracy: 0.82\n",
      "57\n",
      "Accuracy: 0.82\n",
      "58\n",
      "Accuracy: 0.86\n",
      "59\n",
      "Accuracy: 0.78\n",
      "60\n",
      "Accuracy: 0.82\n",
      "61\n",
      "Accuracy: 0.82\n",
      "62\n",
      "Accuracy: 0.78\n",
      "63\n",
      "Accuracy: 0.78\n",
      "64\n",
      "Accuracy: 0.78\n",
      "65\n",
      "Accuracy: 0.8\n",
      "66\n",
      "Accuracy: 0.82\n",
      "67\n",
      "Accuracy: 0.82\n",
      "68\n",
      "Accuracy: 0.9\n",
      "69\n",
      "Accuracy: 0.82\n",
      "70\n",
      "Accuracy: 0.76\n",
      "71\n",
      "Accuracy: 0.76\n",
      "72\n",
      "Accuracy: 0.76\n",
      "73\n",
      "Accuracy: 0.86\n",
      "74\n",
      "Accuracy: 0.9\n",
      "75\n",
      "Accuracy: 0.86\n",
      "76\n",
      "Accuracy: 0.8\n",
      "77\n",
      "Accuracy: 0.8\n",
      "78\n",
      "Accuracy: 0.72\n",
      "79\n",
      "Accuracy: 0.78\n",
      "80\n",
      "Accuracy: 0.8\n",
      "81\n",
      "Accuracy: 0.86\n",
      "82\n",
      "Accuracy: 0.76\n",
      "83\n",
      "Accuracy: 0.82\n",
      "84\n",
      "Accuracy: 0.96\n",
      "85\n",
      "Accuracy: 0.88\n",
      "86\n",
      "Accuracy: 0.7\n",
      "87\n",
      "Accuracy: 0.72\n",
      "88\n",
      "Accuracy: 0.84\n",
      "89\n",
      "Accuracy: 0.84\n",
      "90\n",
      "Accuracy: 0.88\n",
      "91\n",
      "Accuracy: 0.9\n",
      "92\n",
      "Accuracy: 0.8\n",
      "93\n",
      "Accuracy: 0.84\n",
      "94\n",
      "Accuracy: 0.84\n",
      "95\n",
      "Accuracy: 0.86\n",
      "96\n",
      "Accuracy: 0.82\n",
      "97\n",
      "Accuracy: 0.9\n",
      "98\n",
      "Accuracy: 0.84\n",
      "99\n",
      "Accuracy: 0.8\n",
      "100\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    xgb_model = XGBClassifier()\n",
    "    parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "    xgb_model = GridSearchCV(xgb_model, parameters)\n",
    "    xgb_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = xgb_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100XGBoost.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963a645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:26:45.092862Z",
     "start_time": "2023-02-15T05:26:45.092862Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        xgb_model = XGBClassifier()\n",
    "        parameters = {'n_estimators': [50, 100, 200, 300], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "        xgb_model = GridSearchCV(xgb_model, parameters)\n",
    "        xgb_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = xgb_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_XGBoost.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(xgb_model, f\"{col}_XGBoost_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4aa51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "398dadbf",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f94c637a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T06:12:07.866257Z",
     "start_time": "2023-02-17T06:12:01.276308Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "2\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "3\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "4\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.88\n",
      "5\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "6\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "7\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n",
      "8\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "9\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.84\n",
      "10\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "11\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n",
      "12\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "13\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "14\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "15\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "16\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "17\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "18\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "19\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "20\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "21\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "22\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.84\n",
      "23\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "24\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "25\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "26\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.7\n",
      "27\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "28\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "29\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "30\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "31\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "32\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "33\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "34\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n",
      "35\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "36\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "37\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.66\n",
      "38\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.7\n",
      "39\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "40\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "41\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "42\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "43\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.84\n",
      "44\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "45\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "46\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "47\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "48\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "49\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "50\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "51\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.86\n",
      "52\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "53\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "54\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.86\n",
      "55\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "56\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "57\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.84\n",
      "58\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.9\n",
      "59\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "60\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "61\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "62\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.84\n",
      "63\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "64\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "65\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n",
      "66\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "67\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "68\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "69\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "70\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "71\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n",
      "72\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "73\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "74\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "75\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "76\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "77\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "78\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "79\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "80\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.66\n",
      "81\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "82\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n",
      "83\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "84\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "85\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.84\n",
      "86\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.86\n",
      "87\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "88\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "89\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "90\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.72\n",
      "91\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.88\n",
      "92\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "93\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.66\n",
      "94\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.74\n",
      "95\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.86\n",
      "96\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.82\n",
      "97\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.8\n",
      "98\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.76\n",
      "99\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.78\n",
      "100\n",
      "Mean cross-validation accuracy: 0.776\n",
      "Test accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    lda_model = LinearDiscriminantAnalysis(solver='svd', n_components=None)\n",
    "    lda_model.fit(X_train, y_train)\n",
    "    \n",
    "    cv_scores = cross_val_score(lda_model, X, y, cv=10)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    print(f'Mean cross-validation accuracy: {mean_cv_score}')\n",
    "    \n",
    "    predictions = lda_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "    \n",
    "np.savetxt(\"NonMotor_unCateg_100LDA.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5956a9",
   "metadata": {},
   "source": [
    "    solver: LDA has four solvers to choose from, namely svd, lsqr, eigen, and lsqr. The default solver is svd, which is a good choice for small datasets. If you have a larger dataset, you may want to try the lsqr or eigen solvers.\n",
    "    shrinkage: LDA can use shrinkage to improve the estimation of the covariance matrix of the data. Shrinkage can be particularly useful when the number of features is much larger than the number of training samples. The shrinkage parameter can be set to auto to automatically choose the shrinkage intensity, or a float value between 0 and 1 to specify a specific level of shrinkage.\n",
    "    n_components: LDA can also be used for dimensionality reduction, in which case you would set the n_components parameter to a value smaller than the original number of features. This can help to reduce overfitting and speed up training and prediction. However, for classification purposes, you would typically set n_components to None to retain all the features.\n",
    "    \n",
    "Here's a brief explanation of the four solvers available in scikit-learn's LDA implementation:\n",
    "\n",
    "    svd: This is the default solver and is based on singular value decomposition (SVD). It is the most efficient solver for small to moderate-sized datasets, and it works well when the number of samples is much larger than the number of features.\n",
    "\n",
    "    lsqr: This solver is based on a conjugate gradient algorithm, and it is particularly effective for larger datasets. It works by iteratively solving the linear system Ax = b, where A is the input data, b is the target variable, and x is the projection matrix.\n",
    "\n",
    "    eigen: This solver computes the eigenvalues and eigenvectors of the covariance matrix of the input data. It is a good choice when the number of features is much smaller than the number of samples.\n",
    "\n",
    "    eigen-sparse: This is a variation of the eigen solver that is designed for sparse input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c6706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "624df854",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3113251e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T06:12:45.521347Z",
     "start_time": "2023-02-17T06:12:39.831350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.6\n",
      "3\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.58\n",
      "4\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "5\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "7\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "8\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.8\n",
      "9\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.58\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "11\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.64\n",
      "12\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "13\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "14\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.62\n",
      "15\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.64\n",
      "16\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "17\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "19\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "20\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "22\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.56\n",
      "23\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "24\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "25\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "27\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "28\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "29\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "31\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "32\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "33\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.62\n",
      "34\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "35\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.78\n",
      "36\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.6\n",
      "37\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.6\n",
      "39\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "40\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "41\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.54\n",
      "42\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "44\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "45\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "46\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "47\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.76\n",
      "48\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "49\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.8\n",
      "50\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.62\n",
      "51\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.52\n",
      "52\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.6\n",
      "53\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.64\n",
      "54\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "55\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "57\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.78\n",
      "58\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "59\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "60\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.54\n",
      "61\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "62\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "63\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "65\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "66\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.64\n",
      "67\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.78\n",
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "69\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "70\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.92\n",
      "71\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.64\n",
      "73\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "74\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "75\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n",
      "76\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7\n",
      "77\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.8\n",
      "78\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.62\n",
      "79\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.56\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "81\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.64\n",
      "82\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "83\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "85\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "86\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.62\n",
      "87\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "89\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "90\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.68\n",
      "91\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.8\n",
      "93\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.78\n",
      "94\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.72\n",
      "95\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.74\n",
      "97\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.66\n",
      "98\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.7\n",
      "99\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.5\n",
      "100\n",
      "Mean cross-validation accuracy: 0.6799999999999999\n",
      "Test accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    qda_model = QuadraticDiscriminantAnalysis()\n",
    "    qda_model.fit(X_train, y_train)\n",
    "    \n",
    "    cv_scores = cross_val_score(qda_model, X, y, cv=10)\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    print(f'Mean cross-validation accuracy: {mean_cv_score}')\n",
    "    \n",
    "    predictions = qda_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "    \n",
    "np.savetxt(\"NonMotor_unCateg_100QDA.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb48f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c18201",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c1070f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T08:20:52.348772Z",
     "start_time": "2023-02-17T07:03:21.441964Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Accuracy: 0.74\n",
      "2\n",
      "Accuracy: 0.78\n",
      "3\n",
      "Accuracy: 0.76\n",
      "4\n",
      "Accuracy: 0.8\n",
      "5\n",
      "Accuracy: 0.8\n",
      "6\n",
      "Accuracy: 0.8\n",
      "7\n",
      "Accuracy: 0.74\n",
      "8\n",
      "Accuracy: 0.74\n",
      "9\n",
      "Accuracy: 0.76\n",
      "10\n",
      "Accuracy: 0.78\n",
      "11\n",
      "Accuracy: 0.68\n",
      "12\n",
      "Accuracy: 0.68\n",
      "13\n",
      "Accuracy: 0.92\n",
      "14\n",
      "Accuracy: 0.76\n",
      "15\n",
      "Accuracy: 0.8\n",
      "16\n",
      "Accuracy: 0.82\n",
      "17\n",
      "Accuracy: 0.7\n",
      "18\n",
      "Accuracy: 0.76\n",
      "19\n",
      "Accuracy: 0.74\n",
      "20\n",
      "Accuracy: 0.72\n",
      "21\n",
      "Accuracy: 0.82\n",
      "22\n",
      "Accuracy: 0.84\n",
      "23\n",
      "Accuracy: 0.8\n",
      "24\n",
      "Accuracy: 0.8\n",
      "25\n",
      "Accuracy: 0.76\n",
      "26\n",
      "Accuracy: 0.74\n",
      "27\n",
      "Accuracy: 0.7\n",
      "28\n",
      "Accuracy: 0.82\n",
      "29\n",
      "Accuracy: 0.78\n",
      "30\n",
      "Accuracy: 0.8\n",
      "31\n",
      "Accuracy: 0.78\n",
      "32\n",
      "Accuracy: 0.76\n",
      "33\n",
      "Accuracy: 0.86\n",
      "34\n",
      "Accuracy: 0.78\n",
      "35\n",
      "Accuracy: 0.74\n",
      "36\n",
      "Accuracy: 0.82\n",
      "37\n",
      "Accuracy: 0.78\n",
      "38\n",
      "Accuracy: 0.76\n",
      "39\n",
      "Accuracy: 0.82\n",
      "40\n",
      "Accuracy: 0.88\n",
      "41\n",
      "Accuracy: 0.76\n",
      "42\n",
      "Accuracy: 0.82\n",
      "43\n",
      "Accuracy: 0.58\n",
      "44\n",
      "Accuracy: 0.72\n",
      "45\n",
      "Accuracy: 0.78\n",
      "46\n",
      "Accuracy: 0.88\n",
      "47\n",
      "Accuracy: 0.8\n",
      "48\n",
      "Accuracy: 0.7\n",
      "49\n",
      "Accuracy: 0.78\n",
      "50\n",
      "Accuracy: 0.76\n",
      "51\n",
      "Accuracy: 0.76\n",
      "52\n",
      "Accuracy: 0.78\n",
      "53\n",
      "Accuracy: 0.76\n",
      "54\n",
      "Accuracy: 0.82\n",
      "55\n",
      "Accuracy: 0.74\n",
      "56\n",
      "Accuracy: 0.72\n",
      "57\n",
      "Accuracy: 0.82\n",
      "58\n",
      "Accuracy: 0.7\n",
      "59\n",
      "Accuracy: 0.86\n",
      "60\n",
      "Accuracy: 0.64\n",
      "61\n",
      "Accuracy: 0.76\n",
      "62\n",
      "Accuracy: 0.92\n",
      "63\n",
      "Accuracy: 0.72\n",
      "64\n",
      "Accuracy: 0.78\n",
      "65\n",
      "Accuracy: 0.76\n",
      "66\n",
      "Accuracy: 0.84\n",
      "67\n",
      "Accuracy: 0.82\n",
      "68\n",
      "Accuracy: 0.76\n",
      "69\n",
      "Accuracy: 0.78\n",
      "70\n",
      "Accuracy: 0.78\n",
      "71\n",
      "Accuracy: 0.72\n",
      "72\n",
      "Accuracy: 0.84\n",
      "73\n",
      "Accuracy: 0.78\n",
      "74\n",
      "Accuracy: 0.76\n",
      "75\n",
      "Accuracy: 0.82\n",
      "76\n",
      "Accuracy: 0.82\n",
      "77\n",
      "Accuracy: 0.8\n",
      "78\n",
      "Accuracy: 0.68\n",
      "79\n",
      "Accuracy: 0.76\n",
      "80\n",
      "Accuracy: 0.84\n",
      "81\n",
      "Accuracy: 0.74\n",
      "82\n",
      "Accuracy: 0.74\n",
      "83\n",
      "Accuracy: 0.78\n",
      "84\n",
      "Accuracy: 0.8\n",
      "85\n",
      "Accuracy: 0.76\n",
      "86\n",
      "Accuracy: 0.84\n",
      "87\n",
      "Accuracy: 0.7\n",
      "88\n",
      "Accuracy: 0.7\n",
      "89\n",
      "Accuracy: 0.76\n",
      "90\n",
      "Accuracy: 0.8\n",
      "91\n",
      "Accuracy: 0.8\n",
      "92\n",
      "Accuracy: 0.8\n",
      "93\n",
      "Accuracy: 0.7\n",
      "94\n",
      "Accuracy: 0.8\n",
      "95\n",
      "Accuracy: 0.82\n",
      "96\n",
      "Accuracy: 0.76\n",
      "97\n",
      "Accuracy: 0.7\n",
      "98\n",
      "Accuracy: 0.78\n",
      "99\n",
      "Accuracy: 0.74\n",
      "100\n",
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    mlp_model = MLPClassifier()\n",
    "    parameters = {'hidden_layer_sizes': [(20,10,5), (12,8)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1], \n",
    "                  'max_iter': [5000], \n",
    "                  'activation': ['relu', 'logistic']}\n",
    "    mlp_model = GridSearchCV(mlp_model, parameters)\n",
    "    mlp_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = mlp_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100MLPNeuralNet.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9e8e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:26:45.195403Z",
     "start_time": "2023-02-15T05:26:45.195403Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        mlp_model = MLPClassifier()\n",
    "        parameters = {'hidden_layer_sizes': [(10,), (5,), (10,50), (10,6,2)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1], \n",
    "                  'max_iter': [2000], \n",
    "                  'activation': ['relu', 'logistic']}\n",
    "        mlp_model = GridSearchCV(mlp_model, parameters)\n",
    "        mlp_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = mlp_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_MLPNN.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(mlp_model, f\"{col}_MLPNN_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed12beb",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d3eb558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-17T07:02:37.191554Z",
     "start_time": "2023-02-17T07:02:36.330983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[11  3]\n",
      " [11 25]]\n",
      "0.72\n",
      "2\n",
      "[[ 7  7]\n",
      " [ 9 27]]\n",
      "0.68\n",
      "3\n",
      "[[ 8 13]\n",
      " [ 4 25]]\n",
      "0.66\n",
      "4\n",
      "[[ 8  5]\n",
      " [12 25]]\n",
      "0.66\n",
      "5\n",
      "[[12 11]\n",
      " [ 6 21]]\n",
      "0.66\n",
      "6\n",
      "[[ 8  6]\n",
      " [12 24]]\n",
      "0.64\n",
      "7\n",
      "[[12  2]\n",
      " [ 9 27]]\n",
      "0.78\n",
      "8\n",
      "[[14  5]\n",
      " [ 4 27]]\n",
      "0.82\n",
      "9\n",
      "[[ 8  6]\n",
      " [ 5 31]]\n",
      "0.78\n",
      "10\n",
      "[[10  9]\n",
      " [ 4 27]]\n",
      "0.74\n",
      "11\n",
      "[[11  4]\n",
      " [ 7 28]]\n",
      "0.78\n",
      "12\n",
      "[[ 8 10]\n",
      " [ 7 25]]\n",
      "0.66\n",
      "13\n",
      "[[ 9  5]\n",
      " [12 24]]\n",
      "0.66\n",
      "14\n",
      "[[13  8]\n",
      " [ 5 24]]\n",
      "0.74\n",
      "15\n",
      "[[11  3]\n",
      " [12 24]]\n",
      "0.7\n",
      "16\n",
      "[[16  3]\n",
      " [ 6 25]]\n",
      "0.82\n",
      "17\n",
      "[[ 9  4]\n",
      " [18 19]]\n",
      "0.56\n",
      "18\n",
      "[[11  5]\n",
      " [ 5 29]]\n",
      "0.8\n",
      "19\n",
      "[[12  8]\n",
      " [ 5 25]]\n",
      "0.74\n",
      "20\n",
      "[[ 9  7]\n",
      " [10 24]]\n",
      "0.66\n",
      "21\n",
      "[[10  3]\n",
      " [ 8 29]]\n",
      "0.78\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  3]\n",
      " [10 28]]\n",
      "0.74\n",
      "23\n",
      "[[ 8  7]\n",
      " [ 5 30]]\n",
      "0.76\n",
      "24\n",
      "[[10  4]\n",
      " [ 9 27]]\n",
      "0.74\n",
      "25\n",
      "[[15  7]\n",
      " [ 7 21]]\n",
      "0.72\n",
      "26\n",
      "[[11  8]\n",
      " [ 4 27]]\n",
      "0.76\n",
      "27\n",
      "[[ 8 10]\n",
      " [ 9 23]]\n",
      "0.62\n",
      "28\n",
      "[[13  7]\n",
      " [ 6 24]]\n",
      "0.74\n",
      "29\n",
      "[[ 9  8]\n",
      " [ 9 24]]\n",
      "0.66\n",
      "30\n",
      "[[14  4]\n",
      " [ 7 25]]\n",
      "0.78\n",
      "31\n",
      "[[ 6 10]\n",
      " [ 5 29]]\n",
      "0.7\n",
      "32\n",
      "[[12  8]\n",
      " [ 1 29]]\n",
      "0.82\n",
      "33\n",
      "[[ 7  8]\n",
      " [ 6 29]]\n",
      "0.72\n",
      "34\n",
      "[[11  1]\n",
      " [11 27]]\n",
      "0.76\n",
      "35\n",
      "[[11  7]\n",
      " [14 18]]\n",
      "0.58\n",
      "36\n",
      "[[10  6]\n",
      " [10 24]]\n",
      "0.68\n",
      "37\n",
      "[[ 9  6]\n",
      " [ 8 27]]\n",
      "0.72\n",
      "38\n",
      "[[ 9  7]\n",
      " [ 6 28]]\n",
      "0.74\n",
      "39\n",
      "[[10  7]\n",
      " [ 5 28]]\n",
      "0.76\n",
      "40\n",
      "[[11  6]\n",
      " [ 2 31]]\n",
      "0.84\n",
      "41\n",
      "[[11  3]\n",
      " [10 26]]\n",
      "0.74\n",
      "42\n",
      "[[10  2]\n",
      " [11 27]]\n",
      "0.74\n",
      "43\n",
      "[[ 7  8]\n",
      " [ 9 26]]\n",
      "0.66\n",
      "44\n",
      "[[10  5]\n",
      " [ 8 27]]\n",
      "0.74\n",
      "45\n",
      "[[10  2]\n",
      " [ 7 31]]\n",
      "0.82\n",
      "46\n",
      "[[10 10]\n",
      " [ 3 27]]\n",
      "0.74\n",
      "47\n",
      "[[11  7]\n",
      " [ 5 27]]\n",
      "0.76\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  8]\n",
      " [ 5 27]]\n",
      "0.74\n",
      "49\n",
      "[[11  7]\n",
      " [ 9 23]]\n",
      "0.68\n",
      "50\n",
      "[[14  5]\n",
      " [ 6 25]]\n",
      "0.78\n",
      "51\n",
      "[[11  4]\n",
      " [10 25]]\n",
      "0.72\n",
      "52\n",
      "[[13  6]\n",
      " [ 7 24]]\n",
      "0.74\n",
      "53\n",
      "[[12  7]\n",
      " [ 7 24]]\n",
      "0.72\n",
      "54\n",
      "[[12  6]\n",
      " [ 5 27]]\n",
      "0.78\n",
      "55\n",
      "[[12  4]\n",
      " [13 21]]\n",
      "0.66\n",
      "56\n",
      "[[ 9  4]\n",
      " [ 8 29]]\n",
      "0.76\n",
      "57\n",
      "[[11  7]\n",
      " [ 7 25]]\n",
      "0.72\n",
      "58\n",
      "[[11  7]\n",
      " [ 8 24]]\n",
      "0.7\n",
      "59\n",
      "[[ 9  7]\n",
      " [ 9 25]]\n",
      "0.68\n",
      "60\n",
      "[[ 9  8]\n",
      " [10 23]]\n",
      "0.64\n",
      "61\n",
      "[[14  5]\n",
      " [ 4 27]]\n",
      "0.82\n",
      "62\n",
      "[[11  3]\n",
      " [16 20]]\n",
      "0.62\n",
      "63\n",
      "[[ 5 14]\n",
      " [ 5 26]]\n",
      "0.62\n",
      "64\n",
      "[[14  2]\n",
      " [10 24]]\n",
      "0.76\n",
      "65\n",
      "[[ 7  7]\n",
      " [12 24]]\n",
      "0.62\n",
      "66\n",
      "[[12  7]\n",
      " [ 6 25]]\n",
      "0.74\n",
      "67\n",
      "[[14  6]\n",
      " [ 2 28]]\n",
      "0.84\n",
      "68\n",
      "[[10 10]\n",
      " [ 5 25]]\n",
      "0.7\n",
      "69\n",
      "[[ 9  3]\n",
      " [12 26]]\n",
      "0.7\n",
      "70\n",
      "[[10  7]\n",
      " [ 4 29]]\n",
      "0.78\n",
      "71\n",
      "[[12  7]\n",
      " [ 5 26]]\n",
      "0.76\n",
      "72\n",
      "[[ 7  9]\n",
      " [ 9 25]]\n",
      "0.64\n",
      "73\n",
      "[[ 8  9]\n",
      " [ 5 28]]\n",
      "0.72\n",
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  5]\n",
      " [10 24]]\n",
      "0.7\n",
      "75\n",
      "[[ 9  9]\n",
      " [ 9 23]]\n",
      "0.64\n",
      "76\n",
      "[[12  3]\n",
      " [ 7 28]]\n",
      "0.8\n",
      "77\n",
      "[[16  4]\n",
      " [ 8 22]]\n",
      "0.76\n",
      "78\n",
      "[[ 8 15]\n",
      " [ 7 20]]\n",
      "0.56\n",
      "79\n",
      "[[11  7]\n",
      " [10 22]]\n",
      "0.66\n",
      "80\n",
      "[[11  5]\n",
      " [ 9 25]]\n",
      "0.72\n",
      "81\n",
      "[[11  9]\n",
      " [ 6 24]]\n",
      "0.7\n",
      "82\n",
      "[[12 11]\n",
      " [ 5 22]]\n",
      "0.68\n",
      "83\n",
      "[[ 9  8]\n",
      " [ 7 26]]\n",
      "0.7\n",
      "84\n",
      "[[11  9]\n",
      " [ 6 24]]\n",
      "0.7\n",
      "85\n",
      "[[ 8 16]\n",
      " [ 2 24]]\n",
      "0.64\n",
      "86\n",
      "[[11  4]\n",
      " [ 5 30]]\n",
      "0.82\n",
      "87\n",
      "[[17  6]\n",
      " [ 4 23]]\n",
      "0.8\n",
      "88\n",
      "[[14  5]\n",
      " [ 3 28]]\n",
      "0.84\n",
      "89\n",
      "[[ 9  7]\n",
      " [ 9 25]]\n",
      "0.68\n",
      "90\n",
      "[[10  8]\n",
      " [ 4 28]]\n",
      "0.76\n",
      "91\n",
      "[[11  7]\n",
      " [13 19]]\n",
      "0.6\n",
      "92\n",
      "[[11  6]\n",
      " [ 7 26]]\n",
      "0.74\n",
      "93\n",
      "[[10  6]\n",
      " [19 15]]\n",
      "0.5\n",
      "94\n",
      "[[ 6  9]\n",
      " [ 3 32]]\n",
      "0.76\n",
      "95\n",
      "[[11  9]\n",
      " [ 9 21]]\n",
      "0.64\n",
      "96\n",
      "[[10  6]\n",
      " [ 7 27]]\n",
      "0.74\n",
      "97\n",
      "[[12  8]\n",
      " [ 4 26]]\n",
      "0.76\n",
      "98\n",
      "[[11  7]\n",
      " [ 5 27]]\n",
      "0.76\n",
      "99\n",
      "[[ 9  8]\n",
      " [ 6 27]]\n",
      "0.72\n",
      "100\n",
      "[[13  6]\n",
      " [ 7 24]]\n",
      "0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    X = NonMot1.drop('APPRDX', axis=1)\n",
    "    y = NonMot1['APPRDX']\n",
    "    \n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    # Training the K-NN model on the Training set\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ac = accuracy_score(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print(ac)\n",
    "    output.append(ac)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100KNN.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c8c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:26:45.215515Z",
     "start_time": "2023-02-15T05:26:45.215515Z"
    }
   },
   "source": [
    "\n",
    "#scipy.stats.mode(a, axis=0, nan_policy='propagate', keepdims=None)\n",
    "output = []\n",
    "for i in range(1, 101):\n",
    "    print(i)\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(NonMot1.drop('APPRDX', axis=1), \n",
    "                                                                        NonMot1['APPRDX'], test_size=0.2)\n",
    "    \n",
    "    knn_model = KNeighborsClassifier()\n",
    "    parameters = {'n_neighbors': [5, 10, 15, 20]}\n",
    "    knn_model = GridSearchCV(knn_model, parameters)\n",
    "    knn_model.fit(train_data, train_labels)\n",
    "    \n",
    "    predictions = knn_model.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    output.append(accuracy)\n",
    "\n",
    "np.savetxt(\"NonMotor_unCateg_100KNN.csv\", output, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69a502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-15T05:26:45.245687Z",
     "start_time": "2023-02-15T05:26:45.245687Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in NonMot1.columns:\n",
    "    if col != 'APPRDX':\n",
    "        output = []\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(NonMot1[[col]], \n",
    "                                                                NonMot1['APPRDX'], test_size=0.2)\n",
    "        \n",
    "        knn_model = KNeighborsClassifier()\n",
    "        parameters = {'n_neighbors': [5, 10, 15, 20]}\n",
    "        knn_model = GridSearchCV(knn_model, parameters)\n",
    "        knn_model.fit(train_data, train_labels)\n",
    "        \n",
    "        predictions = knn_model.predict(test_data)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        print(f'Accuracy for column {col}: {accuracy}')\n",
    "        output.append(accuracy)\n",
    "\n",
    "        np.savetxt(f\"{col}_KNN.csv\", output, delimiter=\",\")\n",
    "        joblib.dump(knn_model, f\"{col}_KNN_model.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf0384",
   "metadata": {},
   "source": [
    "# Voting and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712e235",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-02-14T12:08:11.961Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the dataset and split into training and testing sets\n",
    "X, y = NonMot1.drop('APPRDX', axis=1), NonMot1['APPRDX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the base models\n",
    "base_models = [('rf', RandomForestClassifier(n_estimators=100, random_state=1)),\n",
    "               ('ada', AdaBoostClassifier(n_estimators=100, random_state=1)),\n",
    "               ('gb', GradientBoostingClassifier(n_estimators=100, random_state=1)),\n",
    "               ('svc', SVC(probability=True, random_state=1)),\n",
    "               ('knn', KNeighborsClassifier(n_neighbors=5))]\n",
    "\n",
    "# Define the voting ensemble model\n",
    "voting_model = VotingClassifier(estimators=base_models)\n",
    "\n",
    "# Define the stacking ensemble model\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train and evaluate the voting ensemble model\n",
    "voting_model.fit(X_train, y_train)\n",
    "voting_predictions = voting_model.predict(X_test)\n",
    "voting_accuracy = accuracy_score(y_test, voting_predictions)\n",
    "print(f'Voting ensemble accuracy: {voting_accuracy:.4f}')\n",
    "\n",
    "# Train and evaluate the stacking ensemble model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "print(f'Stacking ensemble accuracy: {stacking_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d575b4e",
   "metadata": {},
   "source": [
    "Voting and stacking are two popular ensemble learning techniques in machine learning. They are used to combine the predictions of multiple base models to improve the accuracy and generalization of the final model.\n",
    "\n",
    "Voting: In a voting ensemble, multiple base models are trained on the same training data and their predictions are combined using majority voting. That is, the final prediction is determined by the most frequently predicted class across all of the base models. Voting can be done either by hard voting or soft voting. In hard voting, the class that gets the most votes across all models is the predicted class, while in soft voting, the probabilities of all models are averaged to determine the final prediction. Voting is a simple and effective ensemble technique, but it works best when the base models have low correlation with each other.\n",
    "\n",
    "Stacking: In a stacking ensemble, multiple base models are trained on the same training data and their predictions are used as input to a meta-model, which makes the final prediction. The meta-model is trained on the output of the base models, rather than the original input features. The idea behind stacking is to capture the strengths and weaknesses of the base models and learn how to best combine them. Stacking can be done using different meta-models, such as linear regression, logistic regression, or neural networks. The choice of meta-model depends on the problem domain and the nature of the base models. Stacking is more complex than voting, but it can lead to better performance if done correctly.\n",
    "\n",
    "Overall, both voting and stacking are useful ensemble techniques that can improve the performance of machine learning models. They are particularly useful when the base models have complementary strengths and weaknesses, and when there is a risk of overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159120f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
